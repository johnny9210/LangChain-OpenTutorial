{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResumeRecommendationReview\n",
    "\n",
    "- Author: [Ilgyun Jeong](https://github.com/johnny9210)\n",
    "- Design:\n",
    "- Peer Review:\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "## Overview\n",
    "\n",
    "The ResumeRecommendationReview system is a comprehensive solution designed to simplify and enhance the job application process for individuals seeking corporate positions. The system is divided into two main components, each tailored to address key challenges faced by job seekers:\n",
    "\n",
    "1) Company Recommendation\n",
    "Using advanced matching algorithms, the system analyzes a user’s uploaded resume and compares it with job postings on LinkedIn. Based on this analysis, it identifies and recommends companies that align closely with the candidate’s qualifications, skills, and career aspirations.\n",
    "\n",
    "2) Resume Evaluation and Enhancement\n",
    "For the recommended companies, the system conducts a detailed evaluation of the user’s resume. It highlights strengths, identifies areas for improvement, and provides actionable suggestions for tailoring the resume to better fit the expectations of target roles. This ensures candidates can present their qualifications in the most impactful way possible.\n",
    "\n",
    "By integrating these two components, the ResumeRecommendationReview system streamlines the job application journey, empowering users to:\n",
    "\n",
    "- Discover job opportunities that best match their unique profile.\n",
    "- Optimize their resumes for maximum impact, increasing their chances of securing interviews and job offers.\n",
    "\n",
    "**Key Features**:\n",
    "\n",
    "- **CV/Resume Upload**: \n",
    "  Users begin by uploading their existing CV or resume in a supported file format (e.g., PDF)\n",
    "  The system extracts relevant keywords, experiences, and skill sets to build a user profile.\n",
    "\n",
    "- **Job Matching with LinkedIn Postings**: \n",
    "  The platform automatically scans LinkedIn job listings (and potentially other job boards) for roles that align with the user’s skill set and career interests.\n",
    "  A matching algorithm ranks and recommends a list of the most relevant companies and positions for the candidate to consider.\n",
    "\n",
    "- **Comparison & Evaluation (LLM-as-a-Judge)**  \n",
    "  The system leverages a Large Language Model (LLM) to analyze the uploaded resume and specific job requirements. \n",
    "  It evaluates the alignment between the user's experience and the job description, identifying strengths,  skill gaps, and areas in need of improvement.\n",
    "  Additionally, the system evaluates the recommendation performance using **cosine similarity** to measure the semantic alignment and **NDCG (Normalized Discounted Cumulative Gain)** to assess the ranking quality of the recommendations.\n",
    "  \n",
    "- **Automated Resume Enhancement**: \n",
    "  Based on the LLM evaluation, the system provides a detailed report highlighting sections that need modification.\n",
    "  Suggested edits may include restructuring experience points, emphasizing relevant skills, or adding keywords that match the job posting’s expectations.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Data Preparation and Preprocessing](#data-preparation-and-preprocessing)\n",
    "- [Setting Up ChromaDB and Storing Data](#Setting-Up-ChromaDB-and-Storing-Data)\n",
    "- [Company Recommendation System](#Company-Recommendation-System)\n",
    "- [LLM-Based Resume Evaluation System](#LLM-Based-Resume-Evaluation-System)\n",
    "- [LLM-Based Resume Revise System](#LLM-Based-Resume-Revise-System)\n",
    "\n",
    "### References\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"chromadb\",\n",
    "        \"langchain_chroma\",\n",
    "        \"langchain_openai\",\n",
    "        \"PyMuPDF\",\n",
    "        \"pydantic\",\n",
    "        \"pandas\",\n",
    "        \"kagglehub\",\n",
    "        \"langchain_community\",\n",
    "        \"numpy\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"ResumeRecommendationReview\",\n",
    "        \"UPSTAGE_API_KEY\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Preprocessing\n",
    "\n",
    "This section covers the data preparation and preprocessing steps required for the Resume Recommendation System. The key stages include:\n",
    "\n",
    "- **Processing resume data (PDF)**  \n",
    "- **Processing LinkedIn job postings**  \n",
    "\n",
    "For the LinkedIn job postings data, this tutorial uses the dataset available on Kaggle: [arshkon/linkedin-job-postings](https://www.kaggle.com/arshkon/linkedin-job-postings).  \n",
    "\n",
    "Using the raw data directly to build the recommendation system may lead to suboptimal performance. Therefore, the data is refined and preprocessed to focus specifically on recruitment-related information to enhance the accuracy and relevance of the recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List\n",
    "import kagglehub\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Splitting Configuration\n",
    "\n",
    "Set up configurations to divide the extracted text into manageable sizes, ensuring smooth processing:\n",
    "\n",
    "Parameter Descriptions:\n",
    "- `chunk_size`: The maximum length of each text chunk, ensuring the text is divided into manageable sections.\n",
    "- `chunk_overlap`: The length of overlapping text between chunks, providing continuity and context for downstream tasks.\n",
    "- `separators`: The delimiters used to split the text, such as line breaks or punctuation, to optimize the splitting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Pydantic Model\n",
    "\n",
    "In this section, we define a structured data model using Pydantic, which ensures validation and consistency in the data extracted from resumes. This model is critical for organizing key sections of a resume into a format that the system can analyze effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pydantic model\n",
    "class ResumeSection(BaseModel):\n",
    "    skills: List[str] = Field(description=\"List of job-related technical skills\")\n",
    "    work_experience: List[Dict[str, str]] = Field(\n",
    "        description=\"Work experience (role, description)\"\n",
    "    )\n",
    "    projects: List[Dict[str, str]] = Field(\n",
    "        description=\"Project experience (name, description)\"\n",
    "    )\n",
    "    achievements: List[str] = Field(\n",
    "        description=\"List of major achievements and accomplishments\"\n",
    "    )\n",
    "    education: List[Dict[str, str]] = Field(\n",
    "        description=\"Education information (name, description)\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Configure the PydanticOutputParser\n",
    "parser = PydanticOutputParser(pydantic_object=ResumeSection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Interests in Resumes\n",
    "\n",
    "The `analyze_interests` function is designed to extract and summarize the key areas of interest and research focus from a resume. It uses a **Large Language Model (LLM)** to process the resume text and provide a concise summary, helping to identify the candidate's academic and professional interests effectively.\n",
    "\n",
    "Purpose\n",
    "- Extracts **main areas of interest** and **research focus** from the provided resume text.\n",
    "- Generates a **brief summary** (2-3 sentences) that highlights the candidate's academic and career patterns.\n",
    "- Focuses solely on interests and research areas to provide targeted insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "\n",
    "def analyze_interests(resume_text: str, llm) -> str:\n",
    "    \"\"\"Analyzes the complete resume text to identify key interest areas.\"\"\"\n",
    "    interest_prompt = \"\"\"Analysis this resume text and provide a brief summary (2-3 sentences) \n",
    "    of the person's main areas of interest and research focus. Focus on their academic interests, \n",
    "    research topics, and career patterns.\n",
    "\n",
    "    Resume Text:\n",
    "    {text}\n",
    "\n",
    "    Provide a concise summary focusing ONLY on their interests and research areas.\"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": interest_prompt.format(text=resume_text)}]\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Career Fit in Resumes\n",
    "\n",
    "The `analyze_career_fit` function evaluates a candidate's resume to recommend the most suitable job roles along with their respective fit scores. By leveraging a **Large Language Model (LLM)**, this function identifies key areas of expertise and rates the candidate's suitability for various technical positions.\n",
    "\n",
    "Purpose\n",
    "- Recommends **job roles** based on the candidate's skills, research background, and career trajectory.\n",
    "- Assigns a **fit score** (0.0 to 1.0) for each role, reflecting the candidate's alignment with the position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_career_fit(resume_text: str, llm) -> Dict[str, float]:\n",
    "    \"\"\"Analyzes the resume to recommend suitable job roles and their fit scores.\"\"\"\n",
    "    career_prompt = \"\"\"You are an expert technical recruiter. Analyze this resume and recommend the most suitable job roles.\n",
    "    Focus on the candidate's expertise, research background, and career trajectory.\n",
    "    \n",
    "    Resume Text:\n",
    "    {text}\n",
    "    \n",
    "    Based on their background, rate the candidate's fit (0.0 to 1.0) for different technical roles.\n",
    "    Consider:\n",
    "    - Technical expertise and depth\n",
    "    - Research contributions\n",
    "    - Project complexity\n",
    "    - Educational background\n",
    "    - Career progression\n",
    "    \n",
    "    Return ONLY a JSON object with role-fit pairs, like:\n",
    "    {{\"Research Scientist\": 0.95, \"Machine Learning Engineer\": 0.9, \"Algorithm Engineer\": 0.85}}\n",
    "    \n",
    "    Include only roles with fit score > 0.7. Focus on senior/research level positions if appropriate.\"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": career_prompt.format(text=resume_text)}]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        return json.loads(response.content.strip())\n",
    "    except json.JSONDecodeError:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Resumes to Extract Key Job-Related Information\n",
    "\n",
    "The `process_resume` function analyzes a resume file, extracting and processing key information relevant to job applications. It combines **text extraction**, **interest analysis**, and **career fit evaluation** to generate structured, weighted insights from the resume.\n",
    "\n",
    "### Function Overview\n",
    "\n",
    "Purpose\n",
    "- Extract **key job-related information** from resumes in PDF format.\n",
    "- Use **LLM analysis** to evaluate the candidate's skills, experience, projects, achievements, and education.\n",
    "- Assign **weights** to each section based on relevance to the target job role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_resume(file_path, target_job_title=None):\n",
    "    \"\"\"Analyze a resume to extract key job-related information.\"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    resume_text = \"\"\n",
    "    for page in doc:\n",
    "        resume_text += page.get_text()\n",
    "\n",
    "    # Get interest summary and career fit analysis\n",
    "    interest_summary = analyze_interests(resume_text, llm)\n",
    "    career_fit = analyze_career_fit(resume_text, llm)\n",
    "\n",
    "    prompt_template = \"\"\"You are a professional resume analyst specializing in research and technical roles.\n",
    "    Analyze the resume in detail, focusing on the candidate's expertise level and research background.\n",
    "    \n",
    "    Target Job Title: {target_job_title}\n",
    "    \n",
    "    Resume Content:\n",
    "    {resume_text}\n",
    "    \n",
    "    Extract the information in the following format:\n",
    "    {format_instructions}\n",
    "    \n",
    "    Focus on extracting information most relevant to research and technical roles.\n",
    "    Pay special attention to:\n",
    "    - Research contributions and impact\n",
    "    - Technical depth in each area\n",
    "    - Project complexity and leadership\n",
    "    - Academic achievements and specializations\"\"\"\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # Format the messages\n",
    "    messages = prompt.format_messages(\n",
    "        target_job_title=target_job_title if target_job_title else \"Not specified\",\n",
    "        resume_text=resume_text,\n",
    "        format_instructions=parser.get_format_instructions(),\n",
    "    )\n",
    "\n",
    "    # Perform LLM analysis\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        parsed_sections = parser.parse(response.content)\n",
    "        print(\"Resume analysis completed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Parsing error: {e}\")\n",
    "        print(f\"LLM response: {response.content}\")\n",
    "        return []\n",
    "\n",
    "    # Apply weights based on job relevance\n",
    "    weighted_content = []\n",
    "\n",
    "    # Skills (Weight: 0.25)\n",
    "    if parsed_sections.skills:\n",
    "        skills_text = \" \".join(parsed_sections.skills)\n",
    "        weighted_content.append((skills_text, 0.25))\n",
    "\n",
    "    # Work Experience (Weight: 0.3)\n",
    "    if parsed_sections.work_experience:\n",
    "        experience_text = \"\\n\".join(\n",
    "            [\n",
    "                f\"{exp.get('role', '')}: {exp.get('description', '')}\"\n",
    "                for exp in parsed_sections.work_experience\n",
    "            ]\n",
    "        )\n",
    "        weighted_content.append((experience_text, 0.3))\n",
    "\n",
    "    # Projects (Weight: 0.2)\n",
    "    if parsed_sections.projects:\n",
    "        projects_text = \"\\n\".join(\n",
    "            [\n",
    "                f\"{proj.get('name', '')}: {proj.get('description', '')}\"\n",
    "                for proj in parsed_sections.projects\n",
    "            ]\n",
    "        )\n",
    "        weighted_content.append((projects_text, 0.2))\n",
    "\n",
    "    # Achievements (Weight: 0.1)\n",
    "    if parsed_sections.achievements:\n",
    "        achievements_text = \" \".join(parsed_sections.achievements)\n",
    "        weighted_content.append((achievements_text, 0.1))\n",
    "\n",
    "    # Education (Weight: 0.05)\n",
    "    if parsed_sections.education:\n",
    "        education_text = \"\\n\".join(\n",
    "            [\n",
    "                f\"{edu.get('name', '')}: {edu.get('description', '')}\"\n",
    "                for edu in parsed_sections.education\n",
    "            ]\n",
    "        )\n",
    "        weighted_content.append((education_text, 0.05))\n",
    "\n",
    "    # Add interest summary and career fit (combined weight: 0.1)\n",
    "    if interest_summary or career_fit:\n",
    "        analysis_text = (\n",
    "            \"Research Interests and Focus Areas: \" + interest_summary + \"\\n\\n\"\n",
    "        )\n",
    "        if career_fit:\n",
    "            analysis_text += \"Recommended Roles:\\n\"\n",
    "            for role, score in sorted(\n",
    "                career_fit.items(), key=lambda x: x[1], reverse=True\n",
    "            ):\n",
    "                analysis_text += f\"- {role}: {score:.2f}\\n\"\n",
    "\n",
    "        weighted_content.append((analysis_text, 0.1))\n",
    "\n",
    "        # Adjust other weights to maintain total of 1.0\n",
    "        weighted_content = [\n",
    "            (content, weight * 0.9) for content, weight in weighted_content[:-1]\n",
    "        ] + [weighted_content[-1]]\n",
    "\n",
    "    # Generate chunks for each section\n",
    "    processed_chunks = []\n",
    "    for content, weight in weighted_content:\n",
    "        if content.strip():  # Process only non-empty strings\n",
    "            chunks = text_splitter.split_text(content)\n",
    "            processed_chunks.extend([(chunk, weight) for chunk in chunks])\n",
    "\n",
    "    print(f\"Number of extracted chunks: {len(processed_chunks)}\")\n",
    "    print(\"\\nCareer Analysis Summary:\")\n",
    "    print(\"------------------------\")\n",
    "    print(\"Interests:\", interest_summary)\n",
    "    print(\"\\nRecommended Roles:\")\n",
    "    for role, score in sorted(career_fit.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"- {role}: {score:.2f}\")\n",
    "\n",
    "    return processed_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resume Processing Example\n",
    "\n",
    "Here's an example of how to use the `process_resume` function to extract structured data from a resume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume analysis completed.\n",
      "Number of extracted chunks: 8\n",
      "\n",
      "Career Analysis Summary:\n",
      "------------------------\n",
      "Interests: Joanna Drummond's primary academic interests and research focus lie in computer science, particularly in algorithms, artificial intelligence, and game theory. Her research has extensively explored stable matching problems, preference elicitation, and multi-agent systems, with a specific emphasis on developing algorithms for stable and approximately stable matches using partial information and multi-attribute preferences. Additionally, she has investigated the application of machine learning techniques in educational contexts, such as classifying student engagement and understanding in intelligent tutoring systems.\n",
      "\n",
      "Recommended Roles:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Python Java Julia R Matlab Unix Shell Scripting (bash) Linux Mac OSX Windows LATEX Weka',\n",
       "  0.225),\n",
       " ('Research Intern: Microsoft Research, with Ian Kash and Peter Key, May 2016 to August 2016. Investigated simple pricing for cloud computing.\\nResearch Assistant: University of Toronto, Department of Computer Science, August 2011 to Present. Investigated Bayes-Nash and ex-post equilibria for matching games with imperfect information, stable and approximately stable matching using multi-attribute preference information, and elicitation schemes using multi-attribute based queries.\\nResearch Assistant: University of Pittsburgh Department of Computer Science, April 2008 to May 2011. Investigated the impact of different training set populations on accurately classifying student uncertainty while using a spoken intelligent physics tutor.\\nDirected Study: University of Pittsburgh Department of Computer Science, September 2010 to December 2010. Analyzed and proved properties about an algorithm for dividing n indivisible objects among 2 people.',\n",
       "  0.27),\n",
       " ('Research Assistant: DREU Program, Information Sciences Institute, University of Southern California, June 2010 to August 2010. Applied HMM’s and decision trees to students’ online forum data to categorize students’ posts.',\n",
       "  0.27),\n",
       " ('Stable Matching Problem Research: Investigated stable and approximately stable matching using multi-attribute preference information and elicitation schemes for the stable matching problem.\\nSpoken Intelligent Physics Tutor: Investigated the impact of different training set populations on accurately classifying student uncertainty and applied decision trees to classifying student zoning out.',\n",
       "  0.18000000000000002),\n",
       " ('Program Committee, CoopMAS 2017 Microsoft Research PhD Fellowship Program Finalist, 2016 Reviewer, Algorithmica, 2015 Reviewer, SAGT 2015 Reviewer, AAAI-15 Ontario Graduate Scholarship, 2014 Reviewer, COMSOC-2014 Microsoft Research Graduate Women’s Scholarship Recipient, 2012 Google Anita Borg Memorial Scholarship Finalist, 2012 Ontario Graduate Scholarship, 2012 Awardee of 2011 NSF Graduate Research Fellowship Program DREU Recipient, Chosen for Distributed Research Experience for Undergraduates Program Best Undergraduate Poster, University of Pittsburgh Department of Computer Science 10th Annual Computer Science Day',\n",
       "  0.09000000000000001),\n",
       " ('PhD Computer Science: University of Toronto, (expected) Spring 2017. Co-advisors: Allan Borodin, Kate Larson. Relevant Courses: Algorithms for Solving Propositional Theories; Intro to Graph Theory; Topics in Knowledge Representation and Reasoning; Advanced Microeconomic Theory I. GPA: 3.83\\nM.S. Computer Science: University of Toronto, Spring 2013. Advisor: Craig Boutilier. Relevant Courses: Decision Making under Uncertainty; Advanced Inference Algorithms; Algorithm Design, Analysis, and Theory. GPA: 3.93',\n",
       "  0.045000000000000005),\n",
       " ('B.S. Computer Science and Mathematics: University of Pittsburgh, December 2010. Research Advisor: Diane Litman. Minor: Theatre Arts. Honors: Graduated Magna Cum Laude with Departmental Honors; Dean’s List, Fall 2006 to Spring 2010; Dean’s Stars List, Spring 2007; Upsilon Pi Epsilon, Member. Relevant Courses: Human Language Technologies; Intro to Artificial Intelligence; Advanced Topics in Artificial Intelligence: Speech and Natural Language Processing for Educational Applications (Graduate Course); Algorithm Design; Machine Learning (Graduate Course); Intro to Theory of Computation. GPA: 3.73',\n",
       "  0.045000000000000005),\n",
       " (\"Research Interests and Focus Areas: Joanna Drummond's primary academic interests and research focus lie in computer science, particularly in algorithms, artificial intelligence, and game theory. Her research has extensively explored stable matching problems, preference elicitation, and multi-agent systems, with a specific emphasis on developing algorithms for stable and approximately stable matches using partial information and multi-attribute preferences. Additionally, she has investigated the application of machine learning techniques in educational contexts, such as classifying student engagement and understanding in intelligent tutoring systems.\",\n",
       "  0.1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_resume(\"../data/joannadrummond-cv.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinkedIn Data Preprocessing\n",
    "\n",
    "This step involves loading job posting data and extracting only the necessary details. The dataset used for this tutorial is sourced from **Kaggle**: [arshkon/linkedin-job-postings](https://www.kaggle.com/arshkon/linkedin-job-postings).\n",
    "\n",
    "- `company_name`: The name of the company offering the job posting.\n",
    "- `title`: The title of the job being offered.\n",
    "- `description`: A detailed description of the job, including responsibilities, qualifications, and expectations.\n",
    "- `max_salary`: The maximum salary offered for the position.\n",
    "- `med_salary`: The median salary for the position, providing an average range for the offered pay.\n",
    "- `min_salary`: The minimum salary offered for the position.\n",
    "- `skills_desc`: A list or summary of the required or preferred skills for the position.\n",
    "- `work_type`: The type of work arrangement, such as full-time, part-time, remote, or hybrid.\n",
    "\n",
    "Purpose of These Columns\n",
    "These selected columns are essential for processing job posting data. They allow the system to:\n",
    "\n",
    "- Extract relevant metadata for recommendation and filtering.\n",
    "- Match resumes to job postings based on skills, and job details.\n",
    "- Provide users with clear and actionable job-related information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"arshkon/linkedin-job-postings\", path=\"postings.csv\")\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "selected_columns = [\n",
    "    \"company_name\",\n",
    "    \"title\",\n",
    "    \"description\",\n",
    "    \"max_salary\",\n",
    "    \"med_salary\",\n",
    "    \"min_salary\",\n",
    "    \"skills_desc\",\n",
    "    \"work_type\",\n",
    "]\n",
    "linkedin_df = df[selected_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Cleaning Function\n",
    "\n",
    "Here’s a utility function designed to clean and preprocess text data for better consistency and quality:\n",
    "\n",
    "If there are any `null` values in the company name field, those entries are excluded. (While other fields may also have `null` values, this step focuses only on excluding records with `null` in the company name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", str(text))\n",
    "    # Remove consecutive whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# Remove rows where company_name is empty\n",
    "linkedin_df = linkedin_df.dropna(subset=[\"company_name\"])\n",
    "# Alternative using boolean indexing:\n",
    "# linkedin_df = linkedin_df[linkedin_df['company_name'].notna()]\n",
    "\n",
    "# Clean text data\n",
    "linkedin_df[\"description\"] = linkedin_df[\"description\"].apply(clean_text)\n",
    "linkedin_df[\"skills_desc\"] = linkedin_df[\"skills_desc\"].apply(clean_text)\n",
    "linkedin_df[\"title\"] = linkedin_df[\"title\"].apply(clean_text)\n",
    "\n",
    "# Process salary information\n",
    "for col in [\"max_salary\", \"med_salary\", \"min_salary\"]:\n",
    "    linkedin_df[col] = pd.to_numeric(linkedin_df[col], errors=\"coerce\")\n",
    "\n",
    "# Handle missing values\n",
    "linkedin_df[\"work_type\"] = linkedin_df[\"work_type\"].fillna(\"Not specified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Job Postings Data\n",
    "\n",
    "The `process_job_postings` function integrates and processes job information from a LinkedIn dataset to create structured documents for analysis or recommendation purposes.\n",
    "\n",
    "This function takes a DataFrame of LinkedIn job postings and processes each entry into a standardized format, combining relevant details like company name, job title, required skills, and salary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_job_postings(linkedin_df):\n",
    "    \"\"\"Process and integrate job information\"\"\"\n",
    "    job_documents = []\n",
    "\n",
    "    # Integrate information for each job\n",
    "    for _, row in linkedin_df.iterrows():\n",
    "        # Format salary information\n",
    "        salary_info = \"No salary information\"\n",
    "        if pd.notna(row[\"min_salary\"]) and pd.notna(row[\"max_salary\"]):\n",
    "            salary_info = f\"{row['min_salary']:,.0f} - {row['max_salary']:,.0f}\"\n",
    "        elif pd.notna(row[\"med_salary\"]):\n",
    "            salary_info = f\"Average {row['med_salary']:,.0f}\"\n",
    "\n",
    "        # Integrate job information\n",
    "        job_text = f\"\"\"\n",
    "        Company: {row['company_name']}\n",
    "        Position: {row['title']}\n",
    "        Work Type: {row['work_type']}\n",
    "        Salary: {salary_info}\n",
    "        \n",
    "        Required Skills:\n",
    "        {row['skills_desc']}\n",
    "        \n",
    "        Job Description:\n",
    "        {row['description']}\n",
    "        \"\"\"\n",
    "\n",
    "        # Store with metadata\n",
    "        job_documents.append(\n",
    "            {\n",
    "                \"content\": job_text,\n",
    "                \"metadata\": {\n",
    "                    \"company\": row[\"company_name\"],\n",
    "                    \"title\": row[\"title\"],\n",
    "                    \"work_type\": row[\"work_type\"],\n",
    "                    \"salary\": salary_info,\n",
    "                    \"skills\": row[\"skills_desc\"],\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return job_documents\n",
    "\n",
    "\n",
    "# Usage example\n",
    "job_documents = process_job_postings(linkedin_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up ChromaDB and Storing Data\n",
    "\n",
    "Using ChromaDB for Storing and Retrieving Resume and Job Posting Data\n",
    "In this section, we will explore how to use ChromaDB to store resume and job posting data as vector representations and perform similarity-based searches.\n",
    "\n",
    "What is `ChromaDB`?\n",
    "\n",
    "`ChromaDB` is a vector database that allows text data to be stored as embeddings, enabling efficient similarity-based searches. In our Resume Recommendation System, ChromaDB is used for the following purposes:\n",
    "\n",
    "- Vectorizing Text: Converting resume and job posting text into vector representations.\n",
    "- Efficient Similarity Search: Performing fast searches based on the similarity of embeddings.\n",
    "- Metadata-Based Search and Filtering: Enhancing search results with filters like job title, or company name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Steps\n",
    "Preparing Required Libraries\n",
    "\n",
    "Before starting, import the necessary libraries:\n",
    "\n",
    "Roles of Each Library:\n",
    "\n",
    "- `langchain_community.vectorstores`: Provides integration with ChromaDB.\n",
    "- `langchain_openai`: Enables the use of OpenAI embedding models.\n",
    "- `chromadb`: Provides vector database functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing ChromaDB\n",
    "\n",
    "Set up ChromaDB and create collections:\n",
    "\n",
    "Why Use PersistentClient?\n",
    "- `Permanent Data Storage`: Ensures that data is not lost when the application or session ends.\n",
    "- `Data Persistence Across Sessions`: Allows the system to retain data for use in future queries without requiring re-upload or re-processing.\n",
    "- `Ease of Backup and Recovery`: Provides a reliable way to save and restore data for robustness and fault tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"../data/chromadb\")\n",
    "\n",
    "# Create separate collections for resumes and job postings\n",
    "resume_collection = client.create_collection(\"resumes\")\n",
    "job_collection = client.create_collection(\"jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing Data\n",
    "This step involves saving resume and job posting data into ChromaDB for efficient querying and management.\n",
    "Origin data has too many data, so we use only 500 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume analysis completed.\n",
      "Number of extracted chunks: 7\n",
      "\n",
      "Career Analysis Summary:\n",
      "------------------------\n",
      "Interests: Joanna Drummond's primary academic interests and research focus lie in computer science, particularly in algorithms, artificial intelligence, and game theory. Her research has centered on stable matching problems, preference elicitation, and multi-agent systems, with a strong emphasis on decision-making under uncertainty and the application of machine learning techniques to educational technologies and dialogue systems.\n",
      "\n",
      "Recommended Roles:\n"
     ]
    }
   ],
   "source": [
    "# Prepare resume data\n",
    "resume_file_path = \"../data/joannadrummond-cv.pdf\"  # Path to the resume PDF file\n",
    "resume_chunks = process_resume(\n",
    "    resume_file_path\n",
    ")  # Using the previously defined process_resume function\n",
    "\n",
    "resume_texts = [chunk[0] for chunk in resume_chunks]\n",
    "resume_metadatas = [\n",
    "    {\"source\": \"resume\", \"type\": \"text\", \"weight\": chunk[1]} for chunk in resume_chunks\n",
    "]\n",
    "\n",
    "resume_ids = [f\"resume_chunk_{i}\" for i in range(len(resume_chunks))]\n",
    "\n",
    "# origin data has too many data, so we use only 500 data\n",
    "job_documents_ = job_documents[:500]\n",
    "\n",
    "# Prepare job posting data (same as before)\n",
    "job_texts = [doc[\"content\"] for doc in job_documents_]\n",
    "job_metadatas = [doc[\"metadata\"] for doc in job_documents_]\n",
    "job_ids = [f\"job_{i}\" for i in range(len(job_documents_))]\n",
    "\n",
    "# Generate and store embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Resume embeddings\n",
    "resume_embeddings = embeddings.embed_documents(resume_texts)\n",
    "resume_collection.add(\n",
    "    embeddings=resume_embeddings,\n",
    "    documents=resume_texts,\n",
    "    metadatas=resume_metadatas,\n",
    "    ids=resume_ids,\n",
    ")\n",
    "\n",
    "# Job posting embeddings\n",
    "job_embeddings = embeddings.embed_documents(job_texts)\n",
    "job_collection.add(\n",
    "    embeddings=job_embeddings, documents=job_texts, metadatas=job_metadatas, ids=job_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Job_documents_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '\\n        Company: Corcoran Sawyer Smith\\n        Position: Marketing Coordinator\\n        Work Type: FULL_TIME\\n        Salary: 17 - 20\\n        \\n        Required Skills:\\n        Requirements: We are seeking a College or Graduate Student (can also be completed with school) with a focus in Planning, Architecture, Real Estate Development or Management or General Business. Must be able to work in an extremely fast paced environment and able to multitask and prioritize.\\n        \\n        Job Description:\\n        Job descriptionA leading real estate firm in New Jersey is seeking an administrative Marketing Coordinator with some experience in graphic design. You will be working closely with our fun, kind, ambitious members of the sales team and our dynamic executive team on a daily basis. This is an opportunity to be part of a fast-growing, highly respected real estate brokerage with a reputation for exceptional marketing and extraordinary culture of cooperation and inclusion.Who you are:You must be a well-organized, creative, proactive, positive, and most importantly, kind-hearted person. Please, be responsible, respectful, and cool-under-pressure. Please, be proficient in Adobe Creative Cloud (Indesign, Illustrator, Photoshop) and Microsoft Office Suite. Above all, have fantastic taste and be a good-hearted, fun-loving person who loves working with people and is eager to learn.Role:Our office is a fast-paced environment. You’ll work directly with a Marketing team and communicate daily with other core staff and our large team of agents. This description is a brief overview, but your skills and interests will be considered in what you work on and as the role evolves over time.Agent Assistance- Receive & Organize Marketing Requests from Agents- Track Tasks & Communicate with Marketing team & Agents on Status- Prepare print materials and signs for open houses- Submit Orders to Printers & Communicate & Track DeadlinesGraphic Design & Branding- Managing brand strategy and messaging through website, social media, videos, online advertising, print placement and events- Receive, organize, and prioritize marketing requests from agents- Fulfill agent design requests including postcards, signs, email marketing and property brochures using pre-existing templates and creating custom designs- Maintain brand assets and generic filesEvents & Community- Plan and execute events and promotions- Manage Contacts & Vendors for Event Planning & SponsorshipsOur company is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.Job Type: Full-time Pay: $18-20/hour Expected hours: 35 – 45 per week Benefits:Paid time offSchedule:8 hour shiftMonday to FridayExperience:Marketing: 1 year (Preferred)Graphic design: 2 years (Preferred)Work Location: In person\\n        ',\n",
       " 'metadata': {'company': 'Corcoran Sawyer Smith',\n",
       "  'title': 'Marketing Coordinator',\n",
       "  'work_type': 'FULL_TIME',\n",
       "  'salary': '17 - 20',\n",
       "  'skills': 'Requirements: We are seeking a College or Graduate Student (can also be completed with school) with a focus in Planning, Architecture, Real Estate Development or Management or General Business. Must be able to work in an extremely fast paced environment and able to multitask and prioritize.'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_documents_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company Recommendation System\n",
    "\n",
    "This section focuses on recommending companies that align with the candidate's resume and evaluates the recommendations using two key metrics:\n",
    "\n",
    "1. **Cosine Similarity for Recommendation Evaluation**:  \n",
    "   - Measures the similarity between the candidate's resume and the job posting.  \n",
    "   - A higher cosine similarity score indicates a stronger match between the candidate's profile and the company's job requirements.\n",
    "\n",
    "2. **NDCG (Normalized Discounted Cumulative Gain) for Recommendation Evaluation**:  \n",
    "   - Assesses the quality of the ranking of recommended companies.  \n",
    "   - A higher NDCG score signifies that the most relevant companies appear at the top of the recommendation list, reflecting better ranking performance.\n",
    "\n",
    "### Understanding the Scores\n",
    "- **High Scores**:  \n",
    "   - Indicate a strong alignment between the resume and the recommended companies (Cosine Similarity).  \n",
    "   - Demonstrate that the ranking system effectively prioritizes the most relevant companies (NDCG).  \n",
    "- **Low Scores**:  \n",
    "   - Suggest weaker matches between the resume and job postings or suboptimal ranking of recommendations.  \n",
    "\n",
    "The goal is to achieve high scores in both metrics, ensuring accurate and effective company recommendations for the candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job Recommendation System with Weighted Similarity Search\n",
    "\n",
    "This implementation utilizes a **Job Recommendation System** to match resumes with the most relevant job postings. By combining **cosine similarity** and **weighted scoring**, the system ensures accurate and tailored recommendations.\n",
    "\n",
    "\n",
    "---\n",
    "- **Personalized Matching**: Matches resumes to job postings with high accuracy.\n",
    "- **Flexible Scoring**: Incorporates weighted factors to prioritize specific job attributes.\n",
    "- **Enhanced Readability**: Formats job descriptions for easy review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Weighted Recommendations ===\n",
      "\n",
      "=== Similar Job Posting Search Results ===\n",
      "\n",
      "\n",
      "Job Posting #1\n",
      "================================================================================\n",
      "Company: Symbolica AI\n",
      "Position: Senior Machine Learning Research Engineer\n",
      "Similarity Score: 0.78\n",
      "\n",
      "[Job Description]\n",
      "Company: Symbolica AI\n",
      "Position: Senior Machine Learning Research Engineer\n",
      "Work Type: FULL_TIME\n",
      "Salary: 150,000 - 350,000\n",
      "Required Skills:\n",
      "Job Description:\n",
      "Symbolica is building a new foundation for large-scale AI using structured, interpretable reasoning. We are expanding our team and seeking machine learning research engineers to contribute to the development of our cutting-edge code synthesis and theorem proving models. This is an opportunity to be part of a transformative project and make significant contributions to the field of AI. Responsibilities:Contribute to the design and implementation of machine learning architectures and algorithms for theorem proving, code synthesis, and text generationScale prototype models up using distributed training techniquesDevelop optimized GPU kernels to maximize model performanceIdentify performance bottlenecks using benchmarking and profiling toolsDesign and implement new mechanisms for model parallelismDesign and execute experiments to guide model development process while making effective use of compute budgetDevelop tools to gain insight into model behavior via fine-grained reporting and visualizationMaintain a deep understanding of current techniques in deep learning. Understand, implement, and improve on methods described in machine learning literatureCollaborate with a team of machine learning researchers and engineers to achieve project goals Qualifications:Proficiency with Python deep learning libraries such as PyTorch and JAXExperience with distributed training of large scale deep learning modelsFive years of experience in non-academic machine learning engineering roles, or two years with a relevant PhDNice to have: Proficiency with GPU kernel development using CUDA or Triton In-person in our Bay Area office is preferred, but we will be happy to consider exceptional candidates in other locations. We offer competitive compensation, including equity, health insurance, and 401k benefits. Salary and equity levels are commensurate with experience and location.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Job Posting #2\n",
      "================================================================================\n",
      "Company: Azure Sky Management Consulting\n",
      "Position: Quantitative Researcher - Semi-Systematic Credit\n",
      "Similarity Score: 0.78\n",
      "\n",
      "[Job Description]\n",
      "Company: Azure Sky Management Consulting\n",
      "Position: Quantitative Researcher - Semi-Systematic Credit\n",
      "Work Type: FULL_TIME\n",
      "Salary: No salary information\n",
      "Required Skills:\n",
      "Job Description:\n",
      "Company Insight:The company is a world-leading algorithmic trading house that distinguishes itself from its competitors by its bespoke, bleeding-edge, technological systems which materialize a vast array of heavy return systematic quant-driven strategies. They are leaders in the fields of Mathematics, Computer Science and Engineering, ably processing petabytes of data to conceive complex and undiscovered strategies which range from short to long in holding periods. They are much more than a high-frequency trading firm. After a record year, the highly successful Fixed Income team is looking to invest more than ever before into brand-new systematic strategies across the Credit space. They are looking for a Quant Researcher to join their team in New York and come on board to help in the advancement of their current trading universe, as they seek to add Flow Credit products to their global (though mostly US-centric) systematic credit trading desk. Your Role:Investigate and implement game-changing ways to improve the quantitative analytics library, with a focus on credit flow productsConceive valuation strategies, build mathematical models and translate algorithms into impeccably clean codeApply statistical and predictive modeling techniques to process and analyze large and varied data setsBe open to projects in which traders require a specific piece of functionality, and others where a department-wide strategy needs implementing Experience/Skills Required:1-8 years experience within a front office MM credit quantitative research roleKnowledge of credit flow products (investment grade and/or high-yield corporate bonds, CDS and index pricing etc)Strong research agenda stemming from experience in a research-heavy credit flow MM team and from academic pedigreeReasonable experience in writing production level C++ and/or Python codeThe ability to work collaboratively with a diverse range of technological and quantitative individuals towards shared goals Pre-Application:Please do not apply if you're looking for a contract or remote work.Please ensure you meet the required experience section prior to applying.Allow 1-5 working days for a response to any job enquiry.Your application is subject to our privacy policy, found here: https://www.thurnpartners.com/privacy-policy\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Job Posting #3\n",
      "================================================================================\n",
      "Company: Georgia Tech Research Institute\n",
      "Position: Field Office ISSM - Open Rank-RS-Albuquerque, NM\n",
      "Similarity Score: 0.78\n",
      "\n",
      "[Job Description]\n",
      "Company: Georgia Tech Research Institute\n",
      "Position: Field Office ISSM - Open Rank-RS-Albuquerque, NM\n",
      "Work Type: FULL_TIME\n",
      "Salary: No salary information\n",
      "Required Skills:\n",
      "Job Description:\n",
      "Overview The Georgia Tech Research Institute (GTRI) is the nonprofit, applied research division of the Georgia Institute of Technology (Georgia Tech). Founded in 1934 as the Engineering Experiment Station, GTRI has grown to more than 2,900 employees, supporting eight laboratories in over 20 locations around the country and performing more than $940 million of problem-solving research annually for government and industry. GTRI's renowned researchers combine science, engineering, economics, policy, and technical expertise to solve complex problems for the U.S. federal government, state, and industry. Georgia Tech's Mission and Values Georgia Tech's Mission Is To Develop Leaders Who Advance Technology And Improve The Human Condition. The Institute Has Nine Key Values That Are Foundational To Everything We Do Students are our top priority. We strive for excellence. We thrive on diversity. We celebrate collaboration. We champion innovation. We safeguard freedom of inquiry and expression. We nurture the wellbeing of our community. We act ethically. We are responsible stewards. Over the next decade, Georgia Tech will become an example of inclusive innovation, a leading technological research university of unmatched scale, relentlessly committed to serving the public good; breaking new ground in addressing the biggest local, national, and global challenges and opportunities of our time; making technology broadly accessible; and developing exceptional, principled leaders from all backgrounds ready to produce novel ideas and create solutions with real human impact. Project/Unit Description Cyber Security Division (CSD) is responsible for maintaining the overall security posture of classified systems at GTRI. CSD partners with government agencies to provide support for system accreditation and authorization to process classified information in both Collateral and Special (Special Access Programs (SAP) and Sensitive Compartment Information (SCI)) programs. In addition, CSD handles Communication Security (COMSEC) to ensure information is transmitted in a secure manner and in compliance with government regulations. Job Purpose ISSM is a contractually recognized role described in the National Industrial Security Program Operating Manual. The ISSM oversees the development, implementation, and evaluation of the GTRI information security program including insider threat awareness, facility management, personnel supporting information systems, user training and awareness, and others as appropriate. The ISSM develops, documents, monitors and reports the compliance of GTRI information security program in accordance with Cognizant Security Agency (CSA)-provided guidelines for management, operational, and technical controls. The ISSM leads self-inspections and implements corrective actions for all identified findings and vulnerabilities for information security program at the Field Office. The ISSM serves as the principal advisor on all matters, technical and otherwise, involving the security of classified systems at GTRI. They will coordinate and manage GTRI activities related to classified information systems requirements, assessment and authorization of classified information, classified information systems configuration management, and project management for the life cycle of classified information systems. The ISSM advises GTRI senior management and execute GTRI’s overall strategy for enterprise classified networks and systems to support GTRI’s current and future contractual requirements. Additionally, the ISSM researches policies and regulations, interacts with various agencies and levels of management, and contributes to establishing and maintaining accredited information systems to support GTRI contracts with the U.S. Government. The ISSM researches system vulnerabilities and threats to stay on top of the continuous threat against accredited information systems and networks. The Field Office ISSM is also the Assistant Facility Security Officer (AFSO) to assist the full-time Facility Security Officer (FSO) to ensure compliance with governmental regulations within the National Industrial Security Program Operating Manual (NISPOM), Intelligence Community Directives (ICD), Department of Defense (DoD) 5205.07, Volumes 1-4 and National Security Agency/Central Security Service (NSA/CSS) Policy Manual 3-16 and other regulations related to safeguarding and processing of classified information. The poistion will understand and execute requirements within the NISPOM for the management of Personnel Security, Physical and Environmental protections, Incident Handling, and Security Training and Awareness. Key Responsibilities Coordinate and manage the GTRI FO activities related to classified information systems requirements, assessment and authorization of classified information, classified information systems configuration management, and project management for the life cycle of classified information systems.Develop, maintain, and oversee policies, processes and procedures for the classified Information Systems (IS) security program for the Field Office.Responsible for analyzing network security systems and/or information systems. Safeguard networks against unauthorized modification, destruction, or disclosure.Research, evaluate, design, test, recommend, communicate, and implement new security software or devices.Implement, enforce, communicate, and develop network or other information security policies or security plans for data, software applications, hardware, telecommunications, and computer installations.Interpret, research, and formalize Cyber Security policies, concepts, and measures when designing, procuring, adopting, and developing new IS to ensure compliance with Government policies, guidance, and orders.Research and advise Information Technology (IT) staff of technical security safeguards and operational security measures and provide technical support in implementing security controls.Perform examination and quality control inspections on Information Systems Security protections and safeguards to ensure compliance to Government requirements and standards.Define system security requirements, design system security architecture and develop detailed security designs.Assess information protection effectiveness and plan and manage technical efforts.Manage system security requirements for GTRI’s accredited information systems and assure continuous system compliance.Establish strict program control processes to ensure mitigation of risks and supports obtaining certification and accreditation of systems. This includes process support, analysis support, coordination support, security certification test support, security documentation support, investigations, software research, hardware introduction and release, emerging technology research inspections and periodic audits.Responsible maintaining operational security posture for systems by enforcing established security policies, procedures, and standards.Work with Government security cognizant agencies to identify and manage security findings, risks and mitigations in Plan of Action and Milestones (POA&M).Perform continuous monitoring activities including system security audits and vulnerability scanning and remediation.Periodically conduct of a review of each system's audits and monitor corrective actions until all actions are closed.Ensure Configuration Management (CM) of all associated software, hardware, and security relevant functionsLead incident response process to include document and report to appropriate authorityResearch policies and regulations, interact with various agencies and levels of management, and contribute to establishing and maintaining accredited information systemsResearch system vulnerabilities and threats to stay on top of the continuous threat against accredited systemsPrepare for and participate in self-inspection and Government security vulnerability assessments.Support the formal Security Test and Evaluation (ST&E) required by each government accrediting authority through pre-test preparations, participation in the tests, analysis of the results, and preparation of required reports.Serve as the secondary point of contact for all industrial security concerns.Assist the FSO to manage and support the GTRI Field Office classified security programs.Assist the FSO to develop and administer security education, training, and awareness programs for both cleared and non-cleared personnel.Assist the FSO to maintain visitor control program. Required Minimum Qualifications Must be able to obtain or have a current TS/SCI clearanceBachelor degree in Computer Engineering, Electrical Engineering, Computer Science, Information Assurance, Information Security or related fields.Must possess or be able to obtain CISSP, Security+ and/or other applicable certifications within six months of hire in compliance with DoD Directive 8140/8570, IAM Level II/III baseline certification requirements.Have experience with JSIG, RMF, ICD 503, NIST 800, NISPOM and DAAPMExperience with information systems Incident Response TeamExperience identifying system vulnerabilities and implementing mitigation strategies Preferred Qualifications Active TS/SCI Clearance IAM Level III compliance with CISSPExperience in an environment and culture steeped in teamwork and collaboration working on challenging technical projectsExperience working with XACTA/eMASS Travel Requirements <10% travel Education And Length Of Experience This position vacancy is an open-rank announcement. The final job offer will be dependent on candidate qualifications in alignment with Research Faculty Extension Professional ranks as outlined in section 3.2.1 of the Georgia Tech Faculty Handbook 2 years of related experience with a Bachelor’s degree in Computer Engineering, Electrical Engineering, Computer Science, Information Assurance, Information Security or related fields.0 years of related experience with a Masters’ degree in Computer Engineering, Electrical Engineering, Computer Science, Information Assurance, Information Security or related fields. U.S. Citizenship Requirements Due to our research contracts with the U.S. federal government, candidates for this position must be U.S. Citizens. Clearance Type Required Candidates must be able to obtain and maintain an active security clearance. Benefits At GTRI Comprehensive information on currently offered GTRI benefits, including Health & Welfare, Retirement Plans, Tuition Reimbursement, Time Off, and Professional Development, can be found through this link: https://hr.gatech.edu/benefits Equal Employment Opportunity The Georgia Institute of Technology (Georgia Tech) is an Equal Employment Opportunity Employer. The University is committed to maintaining a fair and respectful environment for all. To that end, and in accordance with federal and state law, Board of Regents policy, and University policy, Georgia Tech provides equal opportunity to all faculty, staff, students, and all other members of the Georgia Tech community, including applicants for admission and/or employment, contractors, volunteers, and participants in institutional programs, activities, or services. Georgia Tech complies with all applicable laws and regulations governing equal opportunity in the workplace and in educational activities. Georgia Tech prohibits discrimination, including discriminatory harassment, on the basis of race, ethnicity, ancestry, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, national origin, age, disability, genetics, or veteran status in its programs, activities, employment, and admissions. This prohibition applies to faculty, staff, students, and all other members of the Georgia Tech community, including affiliates, invitees, and guests. Further, Georgia Tech prohibits citizenship status, immigration status, and national origin discrimination in hiring, firing, and recruitment, except where such restrictions are required in order to comply with law, regulation, executive order, or Attorney General directive, or where they are required by Federal, State, or local government contract. All members of the USG community must adhere to the USG Statement of Core Values, which consists of Integrity, Excellence, Accountability, and Respect. These values shape and fundamentally support our University's work. Additionally, all faculty, staff, and administrators must also be aware of and comply with the Board of Regents and Georgia Institute of Technology's policies on Freedom of Expression and Academic Freedom. More information on these policies can be found here: Board of Regents Policy Manual | University System of Georgia (usg.edu).\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Job Posting #4\n",
      "================================================================================\n",
      "Company: Georgia Tech Research Institute\n",
      "Position: Field Office ISSM - Open Rank-RS-Albuquerque, NM\n",
      "Similarity Score: 0.78\n",
      "\n",
      "[Job Description]\n",
      "Company: Georgia Tech Research Institute\n",
      "Position: Field Office ISSM - Open Rank-RS-Albuquerque, NM\n",
      "Work Type: FULL_TIME\n",
      "Salary: No salary information\n",
      "Required Skills:\n",
      "Job Description:\n",
      "Overview The Georgia Tech Research Institute (GTRI) is the nonprofit, applied research division of the Georgia Institute of Technology (Georgia Tech). Founded in 1934 as the Engineering Experiment Station, GTRI has grown to more than 2,900 employees, supporting eight laboratories in over 20 locations around the country and performing more than $940 million of problem-solving research annually for government and industry. GTRI's renowned researchers combine science, engineering, economics, policy, and technical expertise to solve complex problems for the U.S. federal government, state, and industry. Georgia Tech's Mission and Values Georgia Tech's Mission Is To Develop Leaders Who Advance Technology And Improve The Human Condition. The Institute Has Nine Key Values That Are Foundational To Everything We Do Students are our top priority. We strive for excellence. We thrive on diversity. We celebrate collaboration. We champion innovation. We safeguard freedom of inquiry and expression. We nurture the wellbeing of our community. We act ethically. We are responsible stewards. Over the next decade, Georgia Tech will become an example of inclusive innovation, a leading technological research university of unmatched scale, relentlessly committed to serving the public good; breaking new ground in addressing the biggest local, national, and global challenges and opportunities of our time; making technology broadly accessible; and developing exceptional, principled leaders from all backgrounds ready to produce novel ideas and create solutions with real human impact. Project/Unit Description Cyber Security Division (CSD) is responsible for maintaining the overall security posture of classified systems at GTRI. CSD partners with government agencies to provide support for system accreditation and authorization to process classified information in both Collateral and Special (Special Access Programs (SAP) and Sensitive Compartment Information (SCI)) programs. In addition, CSD handles Communication Security (COMSEC) to ensure information is transmitted in a secure manner and in compliance with government regulations. Job Purpose ISSM is a contractually recognized role described in the National Industrial Security Program Operating Manual. The ISSM oversees the development, implementation, and evaluation of the GTRI information security program including insider threat awareness, facility management, personnel supporting information systems, user training and awareness, and others as appropriate. The ISSM develops, documents, monitors and reports the compliance of GTRI information security program in accordance with Cognizant Security Agency (CSA)-provided guidelines for management, operational, and technical controls. The ISSM leads self-inspections and implements corrective actions for all identified findings and vulnerabilities for information security program at the Field Office. The ISSM serves as the principal advisor on all matters, technical and otherwise, involving the security of classified systems at GTRI. They will coordinate and manage GTRI activities related to classified information systems requirements, assessment and authorization of classified information, classified information systems configuration management, and project management for the life cycle of classified information systems. The ISSM advises GTRI senior management and execute GTRI’s overall strategy for enterprise classified networks and systems to support GTRI’s current and future contractual requirements. Additionally, the ISSM researches policies and regulations, interacts with various agencies and levels of management, and contributes to establishing and maintaining accredited information systems to support GTRI contracts with the U.S. Government. The ISSM researches system vulnerabilities and threats to stay on top of the continuous threat against accredited information systems and networks. The Field Office ISSM is also the Assistant Facility Security Officer (AFSO) to assist the full-time Facility Security Officer (FSO) to ensure compliance with governmental regulations within the National Industrial Security Program Operating Manual (NISPOM), Intelligence Community Directives (ICD), Department of Defense (DoD) 5205.07, Volumes 1-4 and National Security Agency/Central Security Service (NSA/CSS) Policy Manual 3-16 and other regulations related to safeguarding and processing of classified information. The poistion will understand and execute requirements within the NISPOM for the management of Personnel Security, Physical and Environmental protections, Incident Handling, and Security Training and Awareness. Key Responsibilities Coordinate and manage the GTRI FO activities related to classified information systems requirements, assessment and authorization of classified information, classified information systems configuration management, and project management for the life cycle of classified information systems.Develop, maintain, and oversee policies, processes and procedures for the classified Information Systems (IS) security program for the Field Office Responsible for analyzing network security systems and/or information systems.Safeguard networks against unauthorized modification, destruction, or disclosure.Research, evaluate, design, test, recommend, communicate, and implement new security software or devices.Implement, enforce, communicate, and develop network or other information security policies or security plans for data, software applications, hardware, telecommunications, and computer installations.Interpret, research, and formalize Cyber Security policies, concepts, and measures when designing, procuring, adopting, and developing new IS to ensure compliance with Government policies, guidance, and orders.Research and advise Information Technology (IT) staff of technical security safeguards and operational security measures and provide technical support in implementing security controls.Define system security requirements, design system security architecture and develop detailed security designs.Manage system security requirements for GTRI’s accredited information systems and assure continuous system compliance.Establish strict program control processes to ensure mitigation of risks and supports obtaining certification and accreditation of systems. This includes process support, analysis support, coordination support, security certification test support, security documentation support, investigations, software research, hardware introduction and release, emerging technology research inspections and periodic audits.Responsible maintaining operational security posture for systems by enforcing established security policies, procedures, and standards.Work with Government security cognizant agencies to identify and manage security findings, risks and mitigations in Plan of Action and Milestones (POA&M).Perform continuous monitoring activities including system security audits and vulnerability scanning and remediation.Periodically conduct of a review of each system's audits and monitor corrective actions until all actions are closed.Ensure Configuration Management (CM) of all associated software, hardware, and security relevant functionsLead incident response process to include document and report to appropriate authorityResearch system vulnerabilities and threats to stay on top of the continuous threat against accredited systemsPrepare for and participate in self-inspection and Government security vulnerability assessments.Serve as secondary point of contact for all industrial security concerns. Assist FSO to manage and support the GTRI Field Office classified security programs.Assist FSO to develop and administer security education, training, and awareness programs for both cleared and non-cleared personnel.Assist FSO to maintain visitor control program Required Minimum Qualifications Must be able to obtain or have a current TS/SCI clearanceBachelor degree in Computer Engineering, Electrical Engineering, Computer Science, Information Assurance, Information Security or related fields.Must possess or be able to obtain CISSP, Security+ and/or other applicable certifications within six months of hire in compliance with DoD Directive 8140/8570, IAM Level II/III baseline certification requirements.Have experience with JSIG, RMF, ICD 503, NIST 800, NISPOM and DAAPMExperience with information systems Incident Response TeamExperience identifying system vulnerabilities and implementing mitigation strategies. Preferred Qualifications Active TS/SCI ClearanceIAM Level III compliance with CISSPExperience in an environment and culture steeped in teamwork and collaboration working on challenging technical projectsExperience working with XACTA/eMASS Travel Requirements <10% travel Education And Length Of Experience This position vacancy is an open-rank announcement. The final job offer will be dependent on candidate qualifications in alignment with Research Faculty Extension Professional ranks as outlined in section 3.2.1 of the Georgia Tech Faculty Handbook 0 years of related experience with a Bachelor’s degree in Computer Engineering, Electrical Engineering, Computer Science, Information Assurance, Information Security or related fields. U.S. Citizenship Requirements Due to our research contracts with the U.S. federal government, candidates for this position must be U.S. Citizens. Clearance Type Required Candidates must be able to obtain and maintain an active security clearance. Benefits At GTRI Comprehensive information on currently offered GTRI benefits, including Health & Welfare, Retirement Plans, Tuition Reimbursement, Time Off, and Professional Development, can be found through this link: https://hr.gatech.edu/benefits Equal Employment Opportunity The Georgia Institute of Technology (Georgia Tech) is an Equal Employment Opportunity Employer. The University is committed to maintaining a fair and respectful environment for all. To that end, and in accordance with federal and state law, Board of Regents policy, and University policy, Georgia Tech provides equal opportunity to all faculty, staff, students, and all other members of the Georgia Tech community, including applicants for admission and/or employment, contractors, volunteers, and participants in institutional programs, activities, or services. Georgia Tech complies with all applicable laws and regulations governing equal opportunity in the workplace and in educational activities. Georgia Tech prohibits discrimination, including discriminatory harassment, on the basis of race, ethnicity, ancestry, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, national origin, age, disability, genetics, or veteran status in its programs, activities, employment, and admissions. This prohibition applies to faculty, staff, students, and all other members of the Georgia Tech community, including affiliates, invitees, and guests. Further, Georgia Tech prohibits citizenship status, immigration status, and national origin discrimination in hiring, firing, and recruitment, except where such restrictions are required in order to comply with law, regulation, executive order, or Attorney General directive, or where they are required by Federal, State, or local government contract. All members of the USG community must adhere to the USG Statement of Core Values, which consists of Integrity, Excellence, Accountability, and Respect. These values shape and fundamentally support our University's work. Additionally, all faculty, staff, and administrators must also be aware of and comply with the Board of Regents and Georgia Institute of Technology's policies on Freedom of Expression and Academic Freedom. More information on these policies can be found here: Board of Regents Policy Manual | University System of Georgia (usg.edu).\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Job Posting #5\n",
      "================================================================================\n",
      "Company: University of Tehran\n",
      "Position: Researcher\n",
      "Similarity Score: 0.78\n",
      "\n",
      "[Job Description]\n",
      "Company: University of Tehran\n",
      "Position: Researcher\n",
      "Work Type: OTHER\n",
      "Salary: No salary information\n",
      "Required Skills:\n",
      "Job Description:\n",
      "Company Description The University of Tehran, established over seven centuries ago, is a renowned institution of higher education in Iran. It has evolved from a traditional religious school to a modern and academic structure. With campuses located in Tehran, Qom, Karaj, Kish, and Jolfa, the University offers 976 programs in over 500 fields across its 39 faculties and 120 departments. It is home to 15% of the country's Centers of Excellence and houses more than 40 research centers, 3,500 laboratories, and a leading press that publishes over 50 scientific peer-reviewed journals. Role Description This is a full-time on-site role for a Researcher at the University of Tehran's San Diego, CA location. The Researcher will be responsible for conducting research, collecting and analyzing data, preparing reports, and collaborating with other researchers. The role will involve staying up-to-date with the latest developments in the field, attending conferences and seminars, and publishing research findings. Qualifications Strong research skills, including data collection and analysisExcellent written and verbal communication skillsAbility to work effectively in a team and independentlyProficiency in conducting academic research and writing research reportsKnowledge of research methodologies and statistical analysisExperience with research software and toolsStrong organizational and time management skillsA PhD or Master's degree in a relevant field\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "# Retrieve resume and job posting collections\n",
    "resume_collection = client.get_collection(\"resumes\")\n",
    "job_collection = client.get_collection(\"jobs\")\n",
    "\n",
    "# Retrieve stored resume data from ChromaDB\n",
    "resume_results = resume_collection.get(\n",
    "    include=[\"documents\", \"metadatas\"]\n",
    ")  # Use the get() method to fetch all data\n",
    "\n",
    "# Combine resume texts\n",
    "full_resume_text = \" \".join(resume_results[\"documents\"])\n",
    "\n",
    "# Configure embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Convert the resume text into a query vector\n",
    "query_embedding = embeddings.embed_query(full_resume_text)\n",
    "\n",
    "# Use ChromaDB to search for the top 5 most similar job postings\n",
    "job_results = job_collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=5,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"],\n",
    ")\n",
    "\n",
    "# List to store recommended jobs\n",
    "recommended_jobs = []\n",
    "\n",
    "\n",
    "class JobRecommender:\n",
    "    def __init__(self, resume_collection, job_collection):\n",
    "        self.resume_collection = resume_collection\n",
    "        self.job_collection = job_collection\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    def get_resume_text(self) -> str:\n",
    "        \"\"\"Get combined resume text from collection\"\"\"\n",
    "        resume_results = self.resume_collection.get(include=[\"documents\", \"metadatas\"])\n",
    "        return \" \".join(resume_results[\"documents\"])\n",
    "\n",
    "    def get_query_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Convert text to embedding vector\"\"\"\n",
    "        return self.embeddings.embed_query(text)\n",
    "\n",
    "    def weighted_similarity_search(\n",
    "        self, query_embedding: List[float], method: str = \"cosine\", n_results: int = 5\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Search jobs using weighted similarity\n",
    "\n",
    "        Args:\n",
    "            query_embedding: The query embedding vector\n",
    "            method: Similarity method ('cosine' or 'distance')\n",
    "            n_results: Number of results to return\n",
    "        \"\"\"\n",
    "        include_params = [\"documents\", \"metadatas\"]\n",
    "        include_params.append(\"embeddings\" if method == \"cosine\" else \"distances\")\n",
    "\n",
    "        results = self.job_collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=n_results * 2,  # Get more results for reranking\n",
    "            include=include_params,\n",
    "        )\n",
    "\n",
    "        weighted_results = []\n",
    "        for i in range(len(results[\"documents\"][0])):\n",
    "            weight = results[\"metadatas\"][0][i].get(\"weight\", 1.0)\n",
    "\n",
    "            if method == \"cosine\":\n",
    "                doc_embedding = results[\"embeddings\"][0][i]\n",
    "                similarity = np.dot(query_embedding, doc_embedding) / (\n",
    "                    np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)\n",
    "                )\n",
    "            else:  # distance\n",
    "                distance = results[\"distances\"][0][i]\n",
    "                similarity = 1 - distance\n",
    "\n",
    "            weighted_score = similarity * weight\n",
    "            job_desc = self._clean_job_description(results[\"documents\"][0][i])\n",
    "\n",
    "            # Ensure consistent dictionary structure with search_jobs_by_distance\n",
    "            weighted_results.append(\n",
    "                {\n",
    "                    \"company\": results[\"metadatas\"][0][i].get(\"company\", \"Unknown\"),\n",
    "                    \"title\": results[\"metadatas\"][0][i].get(\"title\", \"Unknown\"),\n",
    "                    \"description\": job_desc,\n",
    "                    \"similarity\": weighted_score,  # Use weighted_score as the similarity\n",
    "                    \"metadata\": results[\"metadatas\"][0][i],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Sort by weighted score and get top results\n",
    "        weighted_results.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "        return weighted_results[:n_results]\n",
    "\n",
    "    def _clean_job_description(self, description: str) -> str:\n",
    "        \"\"\"Clean job description text\"\"\"\n",
    "        return description.strip().replace(\"\\n\\n\", \"\\n\")\n",
    "\n",
    "    def print_recommendations(self, recommendations: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Print job recommendations and return the results\"\"\"\n",
    "        print(\"\\n=== Similar Job Posting Search Results ===\")  # Changed from Korean\n",
    "        results = []\n",
    "\n",
    "        for i, job in enumerate(recommendations, 1):\n",
    "            print(f\"\\n\\nJob Posting #{i}\")\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"Company: {job['company']}\")\n",
    "            print(f\"Position: {job['title']}\")\n",
    "            print(f\"Similarity Score: {job['similarity']:.2f}\")\n",
    "            print(\"\\n[Job Description]\")\n",
    "\n",
    "            desc_lines = [\n",
    "                line.strip() for line in job[\"description\"].split(\"\\n\") if line.strip()\n",
    "            ]\n",
    "            for line in desc_lines:\n",
    "                print(line)\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "            # Add results to list  # Changed from Korean\n",
    "            results.append(\n",
    "                {\n",
    "                    \"company\": job[\"company\"],\n",
    "                    \"title\": job[\"title\"],\n",
    "                    \"description\": job[\"description\"],\n",
    "                    \"similarity\": job[\"similarity\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# Execution section modification  # Changed from Korean\n",
    "# Initialize collections\n",
    "resume_collection = client.get_collection(\"resumes\")\n",
    "job_collection = client.get_collection(\"jobs\")\n",
    "\n",
    "# Create recommender instance\n",
    "recommender = JobRecommender(resume_collection, job_collection)\n",
    "\n",
    "# Get resume text and create query embedding\n",
    "resume_text = recommender.get_resume_text()\n",
    "query_embedding = recommender.get_query_embedding(resume_text)\n",
    "\n",
    "# Get recommendations using different methods\n",
    "weighted_recommendations = recommender.weighted_similarity_search(\n",
    "    query_embedding, method=\"cosine\"\n",
    ")\n",
    "\n",
    "# Print results and store them\n",
    "print(\"\\n=== Weighted Recommendations ===\")\n",
    "recommended_jobs = recommender.print_recommendations(weighted_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resume and Job Recommendation Evaluation System\n",
    "\n",
    "This implementation introduces a comprehensive evaluation system for job recommendations based on resumes.\n",
    "\n",
    " The system leverages **Discounted Cumulative Gain (DCG)** and **Normalized Discounted Cumulative Gain (NDCG)** to measure the quality of recommendations. Additionally, precision and recall metrics are calculated for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class ResumeProcessor:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "    def process_resume(self, resume_texts: List[str]) -> str:\n",
    "        \"\"\"Process text using already refined resume_texts\"\"\"\n",
    "        return \" \".join(resume_texts)\n",
    "\n",
    "\n",
    "class NDCGEvaluator:\n",
    "    def __init__(self, model_name=\"gpt-4\", temperature=0.2):\n",
    "        self.llm = ChatOpenAI(model=model_name, temperature=temperature)\n",
    "\n",
    "        # Ground truth generation prompt\n",
    "        self.relevance_prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "        As an expert recruiter, evaluate the relevance between this resume and job posting.\n",
    "        Consider technical skills, experience level, and overall fit.\n",
    "\n",
    "        Resume:\n",
    "        {resume_text}\n",
    "\n",
    "        Job Posting:\n",
    "        {job_text}\n",
    "\n",
    "        Rate the relevance on a scale of 0 to 1, where:\n",
    "        1.0: Perfect match\n",
    "        0.8: Very good match\n",
    "        0.6: Good match\n",
    "        0.4: Moderate match\n",
    "        0.2: Poor match\n",
    "        0.0: No match\n",
    "\n",
    "        Provide only the numerical score, nothing else.\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "    def calculate_dcg(self, relevance_scores: List[float], k: int = None) -> float:\n",
    "        \"\"\"Calculate Discounted Cumulative Gain\n",
    "        Formula: DCG = sum(rel_i / log2(i + 2)) where rel_i is the relevance of item i\n",
    "        \"\"\"\n",
    "        if k is None:\n",
    "            k = len(relevance_scores)\n",
    "        else:\n",
    "            k = min(k, len(relevance_scores))\n",
    "\n",
    "        dcg = 0.0\n",
    "        for i in range(k):\n",
    "            # 2^rel - 1 is commonly used for NDCG calculation to emphasize relevant items\n",
    "            rel = 2 ** relevance_scores[i] - 1\n",
    "            dcg += rel / math.log2(i + 2)\n",
    "        return dcg\n",
    "\n",
    "    def calculate_ndcg(\n",
    "        self, predicted_scores: List[float], ideal_scores: List[float], k: int = None\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate Normalized Discounted Cumulative Gain\n",
    "        NDCG = DCG / IDCG where IDCG is DCG of ideal ordering\n",
    "        \"\"\"\n",
    "        if not predicted_scores or not ideal_scores:\n",
    "            return 0.0\n",
    "\n",
    "        if k is None:\n",
    "            k = len(predicted_scores)\n",
    "        k = min(k, len(predicted_scores))\n",
    "\n",
    "        # Sort ideal scores in descending order\n",
    "        ideal_scores_sorted = sorted(ideal_scores, reverse=True)\n",
    "\n",
    "        dcg = self.calculate_dcg(predicted_scores[:k], k)\n",
    "        idcg = self.calculate_dcg(ideal_scores_sorted[:k], k)\n",
    "\n",
    "        if idcg == 0:\n",
    "            return 0.0\n",
    "\n",
    "        ndcg = dcg / idcg\n",
    "        # Ensure NDCG is between 0 and 1\n",
    "        return max(0.0, min(1.0, ndcg))\n",
    "\n",
    "    def generate_ground_truth(\n",
    "        self, resume_text: str, job_postings: List[Dict]\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"Generate ground truth relevance scores using LLM\"\"\"\n",
    "        ground_truth = {}\n",
    "\n",
    "        for job in job_postings:\n",
    "            if job[\"company\"] == \"Unknown\":\n",
    "                continue\n",
    "\n",
    "            messages = self.relevance_prompt.format_messages(\n",
    "                resume_text=resume_text, job_text=job[\"description\"]\n",
    "            )\n",
    "\n",
    "            response = self.llm.invoke(messages)\n",
    "            try:\n",
    "                score = float(response.content.strip())\n",
    "                ground_truth[job[\"company\"]] = score\n",
    "            except ValueError:\n",
    "                print(f\"Error parsing score for company {job['company']}\")\n",
    "                ground_truth[job[\"company\"]] = 0.0\n",
    "\n",
    "        return ground_truth\n",
    "\n",
    "    def normalize_scores(self, scores: List[float]) -> List[float]:\n",
    "        \"\"\"Normalize scores to 0-1 range\"\"\"\n",
    "        if not scores:\n",
    "            return scores\n",
    "\n",
    "        min_score = min(scores)\n",
    "        max_score = max(scores)\n",
    "\n",
    "        if max_score == min_score:\n",
    "            return [1.0 for _ in scores]\n",
    "\n",
    "        return [(score - min_score) / (max_score - min_score) for score in scores]\n",
    "\n",
    "    def evaluate_recommendations(\n",
    "        self, resume_text: str, recommended_jobs: List[Dict], k: int = None\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"Evaluate recommendations using NDCG\"\"\"\n",
    "        # Filter out Unknown companies\n",
    "        valid_jobs = [job for job in recommended_jobs if job[\"company\"] != \"Unknown\"]\n",
    "\n",
    "        # Generate ground truth scores\n",
    "        ground_truth = self.generate_ground_truth(resume_text, valid_jobs)\n",
    "\n",
    "        # Get predicted scores and normalize them\n",
    "        predicted_scores = [job[\"similarity\"] for job in valid_jobs]\n",
    "        predicted_scores = self.normalize_scores(predicted_scores)\n",
    "\n",
    "        # Get ideal scores in the same order as predictions\n",
    "        ideal_scores = [ground_truth[job[\"company\"]] for job in valid_jobs]\n",
    "\n",
    "        # Calculate NDCG\n",
    "        ndcg_score = self.calculate_ndcg(predicted_scores, ideal_scores, k)\n",
    "\n",
    "        # Additional metrics\n",
    "        if k is None:\n",
    "            k = len(valid_jobs)\n",
    "\n",
    "        # Calculate precision and recall using threshold of 0.6 for relevance\n",
    "        relevant_recommended = sum(1 for score in ideal_scores[:k] if score >= 0.6)\n",
    "        total_relevant = sum(1 for score in ground_truth.values() if score >= 0.6)\n",
    "\n",
    "        precision_at_k = relevant_recommended / k if k > 0 else 0\n",
    "        recall_at_k = relevant_recommended / total_relevant if total_relevant > 0 else 0\n",
    "\n",
    "        return {\n",
    "            \"ndcg\": ndcg_score,\n",
    "            \"precision@k\": precision_at_k,\n",
    "            \"recall@k\": recall_at_k,\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"normalized_predictions\": dict(\n",
    "                zip([job[\"company\"] for job in valid_jobs], predicted_scores)\n",
    "            ),\n",
    "        }\n",
    "\n",
    "\n",
    "def print_evaluation_results(metrics: Dict[str, float], recommended_jobs: List[Dict]):\n",
    "    \"\"\"Print detailed evaluation results\"\"\"\n",
    "    print(\"\\n=== Recommendation Evaluation Results ===\")\n",
    "    print(f\"NDCG Score: {metrics['ndcg']:.3f}\")\n",
    "    print(f\"Precision@k: {metrics['precision@k']:.3f}\")\n",
    "    print(f\"Recall@k: {metrics['recall@k']:.3f}\")\n",
    "\n",
    "    print(\"\\nDetailed Company Scores:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Company':<30} {'Original':<10} {'Normalized':<10} {'Ground Truth':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for job in recommended_jobs:\n",
    "        company = job[\"company\"]\n",
    "        if company == \"Unknown\":\n",
    "            continue\n",
    "\n",
    "        original = job[\"similarity\"]\n",
    "        normalized = metrics[\"normalized_predictions\"].get(company, 0.0)\n",
    "        ground_truth = metrics[\"ground_truth\"].get(company, 0.0)\n",
    "        print(\n",
    "            f\"{company:<30} {original:<10.3f} {normalized:<10.3f} {ground_truth:<10.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excute Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Recommendation Evaluation Results ===\n",
      "NDCG Score: 1.000\n",
      "Precision@k: 0.400\n",
      "Recall@k: 1.000\n",
      "\n",
      "Detailed Company Scores:\n",
      "================================================================================\n",
      "Company                        Original   Normalized Ground Truth\n",
      "--------------------------------------------------------------------------------\n",
      "Symbolica AI                   0.784      1.000      0.600     \n",
      "Azure Sky Management Consulting 0.782      0.637      0.400     \n",
      "Georgia Tech Research Institute 0.781      0.346      0.200     \n",
      "Georgia Tech Research Institute 0.781      0.346      0.200     \n",
      "University of Tehran           0.779      0.000      0.900     \n"
     ]
    }
   ],
   "source": [
    "# Use existing processed resume_texts\n",
    "resume_processor = ResumeProcessor()\n",
    "resume_text = resume_processor.process_resume(resume_texts)\n",
    "\n",
    "evaluator = NDCGEvaluator()\n",
    "metrics = evaluator.evaluate_recommendations(\n",
    "    resume_text=resume_text,\n",
    "    recommended_jobs=recommended_jobs,\n",
    "    k=5,  # Evaluate top-5 recommendations\n",
    ")\n",
    "\n",
    "# Print evaluation results\n",
    "print_evaluation_results(metrics, recommended_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-Based Resume Evaluation System\n",
    "\n",
    "In this section, we implement a system that utilizes a `Large Language Model (LLM)` to compare and analyze resumes against job requirements.\n",
    "\n",
    "---\n",
    "\n",
    "What is `LLM-as-a-Judge`?\n",
    "\n",
    "The `LLM-as-a-Judge` system leverages the advanced reasoning and natural language understanding capabilities of an LLM to serve as an impartial evaluator in the hiring process. By acting as a \"judge,\" the LLM compares a candidate’s resume to job requirements, evaluates their alignment, and provides actionable feedback.\n",
    "\n",
    "Key features of the `LLM-as-a-Judge` system include:\n",
    "- `Contextual Understanding`: It comprehends detailed job descriptions and resumes beyond simple keyword matching, enabling nuanced evaluations.  \n",
    "- `Feedback Generation`: Provides insights into the candidate's strengths and areas for improvement.  \n",
    "- `Decision Support`: Assists hiring managers or applicants by generating a recommendation on the candidate's suitability for the role.\n",
    "\n",
    "This system bridges the gap between human evaluation and automated analysis, ensuring more accurate and tailored results in the recruitment process.\n",
    "\n",
    "---\n",
    "\n",
    "Functionalities\n",
    "\n",
    "The `LLM-as-a-Judge` system provides the following functionalities:\n",
    "\n",
    "- `Detailed Analysis`: Analyzes resumes and job requirements in detail, identifying key qualifications and expectations.  \n",
    "- `Alignment Evaluation`: Assesses how well the candidate's skills and experiences match the job requirements.  \n",
    "- `Strengths and Improvement Areas`: Identifies the candidate's strengths and offers suggestions for improvement.  \n",
    "- `Role Suitability Recommendation`: Provides a final recommendation on whether the candidate is a good fit for the role.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM-Based Resume Evaluation System\n",
    "\n",
    "This system leverages a **Large Language Model (LLM)** to evaluate resumes against job descriptions systematically. It provides detailed feedback based on predefined evaluation criteria, helping candidates understand their strengths, areas for improvement, and overall suitability for specific roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define Pydantic Models\n",
    "class CriterionEvaluation(BaseModel):\n",
    "    \"\"\"Evaluation result for individual criteria\"\"\"\n",
    "\n",
    "    score: int = Field(description=\"Evaluation score (1-5)\")\n",
    "    reasoning: str = Field(description=\"Reasoning behind the score\")\n",
    "    evidence: List[str] = Field(description=\"Evidence found in the resume\")\n",
    "    suggestions: List[str] = Field(description=\"Suggestions for improvement\")\n",
    "\n",
    "\n",
    "class DetailedEvaluation(BaseModel):\n",
    "    \"\"\"Detailed evaluation results\"\"\"\n",
    "\n",
    "    technical_fit: CriterionEvaluation\n",
    "    experience_relevance: CriterionEvaluation\n",
    "    industry_knowledge: CriterionEvaluation\n",
    "    education_qualification: CriterionEvaluation\n",
    "    soft_skills: CriterionEvaluation\n",
    "    overall_score: int = Field(description=\"Overall score (0-100)\")\n",
    "    key_strengths: List[str] = Field(description=\"Key strengths\")\n",
    "    improvement_areas: List[str] = Field(description=\"Areas for improvement\")\n",
    "    final_recommendation: str = Field(description=\"Final recommendation\")\n",
    "\n",
    "\n",
    "class LLMJudge:\n",
    "    def __init__(self, model_name=\"gpt-4o\", temperature=0.1):\n",
    "        self.llm = ChatOpenAI(model=model_name, temperature=temperature)\n",
    "        self.parser = PydanticOutputParser(pydantic_object=DetailedEvaluation)\n",
    "\n",
    "        # Define evaluation criteria\n",
    "        self.evaluation_criteria = {\n",
    "            \"technical_fit\": {\n",
    "                \"weight\": 30,\n",
    "                \"description\": \"Evaluation of technical fit\",\n",
    "                \"subcriteria\": [\n",
    "                    \"required_skills_match\",\n",
    "                    \"tech_stack_relevance\",\n",
    "                    \"skill_proficiency\",\n",
    "                ],\n",
    "            },\n",
    "            \"experience_relevance\": {\n",
    "                \"weight\": 25,\n",
    "                \"description\": \"Evaluation of experience relevance\",\n",
    "                \"subcriteria\": [\"role_similarity\", \"impact_scale\", \"problem_solving\"],\n",
    "            },\n",
    "            \"industry_knowledge\": {\n",
    "                \"weight\": 15,\n",
    "                \"description\": \"Evaluation of industry knowledge\",\n",
    "                \"subcriteria\": [\n",
    "                    \"domain_expertise\",\n",
    "                    \"trend_awareness\",\n",
    "                    \"industry_exposure\",\n",
    "                ],\n",
    "            },\n",
    "            \"education_qualification\": {\n",
    "                \"weight\": 15,\n",
    "                \"description\": \"Evaluation of education and qualifications\",\n",
    "                \"subcriteria\": [\n",
    "                    \"degree_relevance\",\n",
    "                    \"certifications\",\n",
    "                    \"continuous_learning\",\n",
    "                ],\n",
    "            },\n",
    "            \"soft_skills\": {\n",
    "                \"weight\": 15,\n",
    "                \"description\": \"Evaluation of soft skills\",\n",
    "                \"subcriteria\": [\n",
    "                    \"leadership_teamwork\",\n",
    "                    \"communication\",\n",
    "                    \"problem_approach\",\n",
    "                ],\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # Evaluation prompt template\n",
    "        self.prompt_template = \"\"\"You are a professional hiring evaluator.\n",
    "        Evaluate the provided resume objectively and fairly based on the following criteria.\n",
    "\n",
    "        Job Information:\n",
    "        Company: {company_name}\n",
    "        Position: {position}\n",
    "        Job Description: {job_description}\n",
    "\n",
    "        Resume Content:\n",
    "        {resume_text}\n",
    "\n",
    "        Evaluation Criteria:\n",
    "        {evaluation_criteria}\n",
    "\n",
    "        Guidelines for Evaluation:\n",
    "        1. Assign a score from 1-5 for each evaluation area and provide detailed reasoning.\n",
    "        2. Scoring criteria:\n",
    "           5: Outstanding - Exceeds expectations significantly\n",
    "           4: Excellent - Meets and slightly exceeds expectations\n",
    "           3: Adequate - Meets expectations\n",
    "           2: Needs Improvement - Falls slightly short of expectations\n",
    "           1: Poor - Falls significantly short of expectations\n",
    "        3. Provide specific evidence found in the resume for each area.\n",
    "        4. Offer concrete suggestions for improvement.\n",
    "\n",
    "        Provide the evaluation results in the following format:\n",
    "        {format_instructions}\n",
    "        \"\"\"\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_template(\n",
    "            template=self.prompt_template,\n",
    "            partial_variables={\n",
    "                \"format_instructions\": self.parser.get_format_instructions(),\n",
    "                \"evaluation_criteria\": json.dumps(\n",
    "                    self.evaluation_criteria, indent=2, ensure_ascii=False\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def evaluate(self, resume_text: str, job_info: dict) -> DetailedEvaluation:\n",
    "        \"\"\"Perform resume evaluation\"\"\"\n",
    "        try:\n",
    "            messages = self.prompt.format_messages(\n",
    "                company_name=job_info.get(\"company\", \"Unknown\"),\n",
    "                position=job_info.get(\"position\", \"Unknown\"),\n",
    "                job_description=job_info.get(\"description\", \"\"),\n",
    "                resume_text=resume_text,\n",
    "            )\n",
    "\n",
    "            response = self.llm.invoke(messages)\n",
    "            evaluation = self.parser.parse(response.content)\n",
    "            return evaluation\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during evaluation: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "class ResumeEvaluationSystem:\n",
    "    def __init__(self):\n",
    "        self.resume_processor = ResumeProcessor()\n",
    "        self.judge = LLMJudge()\n",
    "\n",
    "    def evaluate_with_recommendations(\n",
    "        self, resume_path: str, recommended_jobs: List[dict], top_n: int = 3\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Evaluate the resume for the recommended jobs\"\"\"\n",
    "        # Extract resume text\n",
    "        resume_text = self.resume_processor.process_resume(resume_path)\n",
    "\n",
    "        # Select top N jobs\n",
    "        sorted_jobs = sorted(\n",
    "            recommended_jobs, key=lambda x: x[\"similarity\"], reverse=True\n",
    "        )[:top_n]\n",
    "        evaluations = []\n",
    "\n",
    "        for job in sorted_jobs:\n",
    "            job_info = {\n",
    "                \"company\": job[\"company\"],\n",
    "                \"position\": job[\"title\"],\n",
    "                \"description\": job[\"description\"],\n",
    "                \"similarity_score\": job[\"similarity\"],\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                # Perform evaluation\n",
    "                evaluation = self.judge.evaluate(resume_text, job_info)\n",
    "\n",
    "                # Generate evaluation report\n",
    "                report = format_evaluation_report(evaluation)\n",
    "\n",
    "                evaluations.append(\n",
    "                    {\"job_info\": job_info, \"evaluation\": evaluation, \"report\": report}\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating for {job_info['company']}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        return evaluations\n",
    "\n",
    "\n",
    "def format_evaluation_report(evaluation: DetailedEvaluation) -> str:\n",
    "    \"\"\"Format evaluation results into a report\"\"\"\n",
    "    output = []\n",
    "    output.append(\"\\n📊 Resume Evaluation Report\")\n",
    "    output.append(\"=\" * 50)\n",
    "\n",
    "    output.append(f\"\\n💡 Overall Score: {evaluation.overall_score}/100\\n\")\n",
    "\n",
    "    # Evaluation by criteria\n",
    "    criteria_items = [\n",
    "        (\"🔧 Technical Fit (30%)\", evaluation.technical_fit),\n",
    "        (\"👔 Experience Relevance (25%)\", evaluation.experience_relevance),\n",
    "        (\"🎯 Industry Knowledge (15%)\", evaluation.industry_knowledge),\n",
    "        (\"📚 Education Qualification (15%)\", evaluation.education_qualification),\n",
    "        (\"🤝 Soft Skills (15%)\", evaluation.soft_skills),\n",
    "    ]\n",
    "\n",
    "    for title, criterion in criteria_items:\n",
    "        output.append(f\"\\n{title}\")\n",
    "        output.append(f\"Score: {criterion.score}/5\")\n",
    "        output.append(f\"Reasoning: {criterion.reasoning}\")\n",
    "        output.append(\"Evidence Found:\")\n",
    "        for evidence in criterion.evidence:\n",
    "            output.append(f\"  • {evidence}\")\n",
    "        output.append(\"Suggestions:\")\n",
    "        for suggestion in criterion.suggestions:\n",
    "            output.append(f\"  • {suggestion}\")\n",
    "\n",
    "    # Overall evaluation\n",
    "    output.append(\"\\n📋 Overall Evaluation\")\n",
    "    output.append(\"-\" * 30)\n",
    "\n",
    "    output.append(\"\\n💪 Key Strengths:\")\n",
    "    for strength in evaluation.key_strengths:\n",
    "        output.append(f\"  • {strength}\")\n",
    "\n",
    "    output.append(\"\\n📈 Areas for Improvement:\")\n",
    "    for area in evaluation.improvement_areas:\n",
    "        output.append(f\"  • {area}\")\n",
    "\n",
    "    output.append(\"\\n🎯 Final Recommendation:\")\n",
    "    output.append(f\"{evaluation.final_recommendation}\")\n",
    "\n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "def print_comprehensive_report(evaluations: List[Dict]):\n",
    "    \"\"\"Display the complete evaluation results\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"📋 Comprehensive Resume Evaluation Report\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for idx, eval_result in enumerate(evaluations, 1):\n",
    "        job_info = eval_result[\"job_info\"]\n",
    "        evaluation = eval_result[\"evaluation\"]\n",
    "\n",
    "        print(f\"\\n{idx}. {job_info['company']} - {job_info['position']}\")\n",
    "        print(f\"Recommendation Similarity Score: {job_info['similarity_score']:.2f}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(eval_result[\"report\"])\n",
    "        print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excute Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume analysis completed.\n",
      "Number of extracted chunks: 7\n",
      "\n",
      "Career Analysis Summary:\n",
      "------------------------\n",
      "Interests: Joanna Drummond's main areas of interest and research focus are in computer science, particularly in algorithms, artificial intelligence, and stable matching problems. Her research has extensively explored topics such as stable and approximately stable matching using multi-attribute preference information, preference elicitation, and the application of machine learning techniques to educational technologies and dialogue systems. She has also investigated decision-making under uncertainty and the impact of dialogue content on learning outcomes.\n",
      "\n",
      "Recommended Roles:\n",
      "Evaluating resume...\n",
      "\n",
      "================================================================================\n",
      "📋 Comprehensive Resume Evaluation Report\n",
      "================================================================================\n",
      "\n",
      "1. Symbolica AI - Senior Machine Learning Research Engineer\n",
      "Recommendation Similarity Score: 0.78\n",
      "--------------------------------------------------\n",
      "\n",
      "📊 Resume Evaluation Report\n",
      "==================================================\n",
      "\n",
      "💡 Overall Score: 65/100\n",
      "\n",
      "\n",
      "🔧 Technical Fit (30%)\n",
      "Score: 3/5\n",
      "Reasoning: The candidate has a strong background in computer science and AI, with proficiency in Python, which is relevant for the role. However, there is no explicit mention of experience with PyTorch, JAX, or distributed training techniques, which are crucial for the position.\n",
      "Evidence Found:\n",
      "  • Proficiency in Python\n",
      "  • Research experience in AI and algorithms\n",
      "Suggestions:\n",
      "  • Gain experience with PyTorch and JAX\n",
      "  • Familiarize with distributed training techniques\n",
      "\n",
      "👔 Experience Relevance (25%)\n",
      "Score: 2/5\n",
      "Reasoning: The candidate has extensive research experience but lacks direct industry experience in machine learning engineering roles. The roles listed are primarily academic, which may not fully align with the job's requirements for non-academic experience.\n",
      "Evidence Found:\n",
      "  • Research Assistant at University of Toronto since 2011\n",
      "  • Research Intern at Microsoft Research\n",
      "Suggestions:\n",
      "  • Seek industry roles to gain practical machine learning engineering experience\n",
      "  • Engage in projects that involve large-scale model deployment\n",
      "\n",
      "🎯 Industry Knowledge (15%)\n",
      "Score: 3/5\n",
      "Reasoning: The candidate has a solid understanding of AI and algorithms, but there is limited evidence of exposure to current industry trends and large-scale AI applications.\n",
      "Evidence Found:\n",
      "  • Research interests in algorithms and AI\n",
      "  • PhD in Computer Science\n",
      "Suggestions:\n",
      "  • Stay updated with industry trends in AI\n",
      "  • Participate in industry conferences and workshops\n",
      "\n",
      "📚 Education Qualification (15%)\n",
      "Score: 5/5\n",
      "Reasoning: The candidate has an excellent educational background with a PhD in Computer Science, which is highly relevant for the role.\n",
      "Evidence Found:\n",
      "  • PhD in Computer Science from University of Toronto\n",
      "  • MS in Computer Science with a high GPA\n",
      "Suggestions:\n",
      "  • Continue engaging in postdoctoral research or advanced courses\n",
      "\n",
      "🤝 Soft Skills (15%)\n",
      "Score: 3/5\n",
      "Reasoning: The resume does not provide explicit evidence of soft skills such as leadership, teamwork, or communication, although the candidate's academic roles may imply some level of these skills.\n",
      "Evidence Found:\n",
      "  • Teaching Assistant at University of Toronto\n",
      "Suggestions:\n",
      "  • Highlight specific examples of teamwork and leadership in the resume\n",
      "  • Develop communication skills through presentations and collaborations\n",
      "\n",
      "📋 Overall Evaluation\n",
      "------------------------------\n",
      "\n",
      "💪 Key Strengths:\n",
      "  • Strong educational background\n",
      "  • Proficiency in Python and AI research\n",
      "\n",
      "📈 Areas for Improvement:\n",
      "  • Lack of industry experience\n",
      "  • Limited exposure to required technical skills\n",
      "\n",
      "🎯 Final Recommendation:\n",
      "The candidate has a strong academic background but needs to gain more industry experience and specific technical skills relevant to the role. Consider for roles that can leverage research expertise while providing industry exposure.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Resume file path\n",
    "resume_path = \"../data/joannadrummond-cv.pdf\"\n",
    "\n",
    "# Initialize evaluation system\n",
    "evaluation_system = ResumeEvaluationSystem()\n",
    "\n",
    "# First, get the resume text\n",
    "resume_chunks = process_resume(resume_path)\n",
    "resume_text = \" \".join([chunk[0] for chunk in resume_chunks])\n",
    "\n",
    "# Perform resume evaluation\n",
    "print(\"Evaluating resume...\")\n",
    "evaluations = evaluation_system.evaluate_with_recommendations(\n",
    "    resume_text,  # Pass the actual resume text instead of the path\n",
    "    recommended_jobs=recommended_jobs,\n",
    "    top_n=1,\n",
    ")\n",
    "\n",
    "# Print comprehensive report\n",
    "print_comprehensive_report(evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-Based Resume Revise System\n",
    "\n",
    "This tutorial demonstrates how to create a system that evaluates and improves resumes using a **Large Language Model (LLM)**. \n",
    "\n",
    "The system provides actionable suggestions to optimize resumes for specific job descriptions, enhancing the candidate’s chances of securing a role.\n",
    "\n",
    "---\n",
    "\n",
    "Key Components\n",
    "\n",
    "1. **EnhancementSuggestion Model**\n",
    "The `EnhancementSuggestion` model defines the structure for improvement suggestions:\n",
    "- **`section`**: The specific resume section being improved (e.g., \"Skills\" or \"Work Experience\").\n",
    "- **`current_content`**: The original content of the section.\n",
    "- **`improved_content`**: The suggested improvement for the section.\n",
    "- **`explanation`**: A detailed explanation of why the improvement is recommended.\n",
    "\n",
    "---\n",
    "\n",
    "2. **ResumeEnhancement Model**\n",
    "The `ResumeEnhancement` model provides a holistic improvement report:\n",
    "- **`improvements`**: A list of section-specific suggestions.\n",
    "- **`keyword_optimization`**: Suggested keywords to include in the resume for optimization.\n",
    "- **`general_suggestions`**: Overall suggestions for structure and presentation.\n",
    "- **`action_items`**: Practical, actionable items for the candidate to implement.\n",
    "\n",
    "---\n",
    "\n",
    "3. **ResumeEnhancementSystem**\n",
    "This class integrates LLM-based analysis to generate detailed improvement suggestions for resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class EnhancementSuggestion(BaseModel):\n",
    "    \"\"\"Suggestions for improvement for each resume section\"\"\"\n",
    "\n",
    "    section: str = Field(description=\"Resume section\")\n",
    "    current_content: str = Field(description=\"Current content\")\n",
    "    improved_content: str = Field(description=\"Suggested improvement\")\n",
    "    explanation: str = Field(description=\"Reason for the improvement and explanation\")\n",
    "\n",
    "\n",
    "class ResumeEnhancement(BaseModel):\n",
    "    \"\"\"Overall suggestions for resume improvement\"\"\"\n",
    "\n",
    "    improvements: List[EnhancementSuggestion] = Field(\n",
    "        description=\"Suggestions for each section\"\n",
    "    )\n",
    "    keyword_optimization: List[str] = Field(description=\"Keywords to optimize\")\n",
    "    general_suggestions: List[str] = Field(description=\"General suggestions\")\n",
    "    action_items: List[str] = Field(description=\"Actionable items\")\n",
    "\n",
    "\n",
    "class ResumeEnhancementSystem:\n",
    "    def __init__(self, model_name=\"gpt-4o\", temperature=0.1):\n",
    "        self.llm = ChatOpenAI(model=model_name, temperature=temperature)\n",
    "        self.parser = PydanticOutputParser(pydantic_object=ResumeEnhancement)\n",
    "\n",
    "        # Prompt template for generating improvement suggestions\n",
    "        self.prompt_template = \"\"\"You are a professional resume consultant.\n",
    "        Based on the provided evaluation results, offer detailed and actionable suggestions for improving the resume.\n",
    "\n",
    "        Current Resume:\n",
    "        {resume_text}\n",
    "\n",
    "        Evaluation Results:\n",
    "        {evaluation_results}\n",
    "\n",
    "        Job Information:\n",
    "        {job_info}\n",
    "\n",
    "        Please include the following considerations when making your suggestions:\n",
    "        1. Specific improvement suggestions for each section\n",
    "        2. Key job-related keywords\n",
    "        3. General structural and expression improvements\n",
    "        4. Short-term and long-term actionable items\n",
    "\n",
    "        Pay particular attention to the following:\n",
    "        - Emphasize areas with high scores\n",
    "        - Provide concrete solutions for areas with low scores\n",
    "        - Tailor suggestions to the characteristics of the job\n",
    "        - Ensure realistic and actionable recommendations\n",
    "\n",
    "        Provide the improvement suggestions in the following format:\n",
    "        {format_instructions}\n",
    "        \"\"\"\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_template(\n",
    "            template=self.prompt_template,\n",
    "            partial_variables={\n",
    "                \"format_instructions\": self.parser.get_format_instructions()\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def generate_improvements(\n",
    "        self, resume_text: str, evaluation_results: List[Dict], job_info: Dict\n",
    "    ) -> ResumeEnhancement:\n",
    "        \"\"\"Generate improvement suggestions based on the evaluation results\"\"\"\n",
    "        try:\n",
    "            # Serialize evaluation_results (if DetailedEvaluation objects are included)\n",
    "            evaluation_data = [\n",
    "                (\n",
    "                    eval_result.model_dump()\n",
    "                    if hasattr(eval_result, \"model_dump\")\n",
    "                    else eval_result\n",
    "                )\n",
    "                for eval_result in evaluation_results\n",
    "            ]\n",
    "\n",
    "            messages = self.prompt.format_messages(\n",
    "                resume_text=resume_text,\n",
    "                evaluation_results=json.dumps(\n",
    "                    evaluation_data, ensure_ascii=False, indent=2\n",
    "                ),\n",
    "                job_info=json.dumps(job_info, ensure_ascii=False, indent=2),\n",
    "            )\n",
    "\n",
    "            response = self.llm.invoke(messages)\n",
    "            suggestions = self.parser.parse(response.content)\n",
    "            return suggestions\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error while generating improvement suggestions: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "def format_enhancement_report(enhancement: ResumeEnhancement) -> str:\n",
    "    \"\"\"Format the improvement suggestions into a report\"\"\"\n",
    "    output = []\n",
    "    output.append(\"\\n📝 Resume Improvement Report\")\n",
    "    output.append(\"=\" * 50)\n",
    "\n",
    "    # Section-specific suggestions\n",
    "    output.append(\"\\n📋 Section-Specific Improvements\")\n",
    "    output.append(\"-\" * 30)\n",
    "    for improvement in enhancement.improvements:\n",
    "        output.append(f\"\\n[{improvement.section}]\")\n",
    "        output.append(\"Current:\")\n",
    "        output.append(f\"  {improvement.current_content}\")\n",
    "        output.append(\"Improved:\")\n",
    "        output.append(f\"  {improvement.improved_content}\")\n",
    "        output.append(\"Reason:\")\n",
    "        output.append(f\"  {improvement.explanation}\")\n",
    "\n",
    "    # Keyword optimization\n",
    "    output.append(\"\\n🔍 Recommended Keywords\")\n",
    "    output.append(\"-\" * 30)\n",
    "    for keyword in enhancement.keyword_optimization:\n",
    "        output.append(f\"• {keyword}\")\n",
    "\n",
    "    # General suggestions\n",
    "    output.append(\"\\n💡 General Suggestions\")\n",
    "    output.append(\"-\" * 30)\n",
    "    for suggestion in enhancement.general_suggestions:\n",
    "        output.append(f\"• {suggestion}\")\n",
    "\n",
    "    # Action items\n",
    "    output.append(\"\\n✅ Actionable Steps\")\n",
    "    output.append(\"-\" * 30)\n",
    "    for item in enhancement.action_items:\n",
    "        output.append(f\"• {item}\")\n",
    "\n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "class IntegratedResumeSystem:\n",
    "    \"\"\"A system combining evaluation and improvement\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.evaluation_system = ResumeEvaluationSystem()\n",
    "        self.enhancement_system = ResumeEnhancementSystem()\n",
    "\n",
    "    def analyze_and_improve(\n",
    "        self, resume_path: str, recommended_jobs: List[dict], top_n: int = 3\n",
    "    ):\n",
    "        \"\"\"Perform integrated resume evaluation and improvement suggestions\"\"\"\n",
    "        try:\n",
    "            # First, process the resume to get the text content\n",
    "            resume_chunks = process_resume(resume_path)\n",
    "            resume_text = \" \".join([chunk[0] for chunk in resume_chunks])\n",
    "\n",
    "            # 1. Perform resume evaluation\n",
    "            print(\"Evaluating the resume...\")\n",
    "            evaluations = self.evaluation_system.evaluate_with_recommendations(\n",
    "                resume_text,  # Pass the processed text instead of path\n",
    "                recommended_jobs=recommended_jobs,\n",
    "                top_n=top_n,\n",
    "            )\n",
    "\n",
    "            # 2. Generate improvement suggestions for each recommended job\n",
    "            print(\"Generating improvement suggestions...\")\n",
    "            improvements = []\n",
    "\n",
    "            for eval_result in evaluations:\n",
    "                job_info = eval_result[\"job_info\"]\n",
    "                evaluation = eval_result[\"evaluation\"]\n",
    "\n",
    "                # Generate improvement suggestions using the already processed resume text\n",
    "                enhancement = self.enhancement_system.generate_improvements(\n",
    "                    resume_text=resume_text,  # Use the processed text\n",
    "                    evaluation_results=[evaluation.model_dump()],\n",
    "                    job_info=job_info,\n",
    "                )\n",
    "\n",
    "                improvements.append(\n",
    "                    {\n",
    "                        \"job_info\": job_info,\n",
    "                        \"evaluation\": evaluation,\n",
    "                        \"enhancement\": enhancement,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            return improvements\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during analysis and improvement: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excute Evaluation\n",
    "\n",
    "you can choose how many jobs you want to evaluate by changing the `top_n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume analysis completed.\n",
      "Number of extracted chunks: 9\n",
      "\n",
      "Career Analysis Summary:\n",
      "------------------------\n",
      "Interests: Joanna Drummond's main areas of interest and research focus are in computer science, particularly in algorithms, artificial intelligence, and stable matching problems. Her research involves exploring strategy-proofness, preference elicitation, and stable matching with partial preferences, as well as investigating the impact of dialogue systems on learning and student engagement. She has a strong background in decision-making under uncertainty and has applied her expertise to various educational and computational social choice contexts.\n",
      "\n",
      "Recommended Roles:\n",
      "Evaluating the resume...\n",
      "Generating improvement suggestions...\n",
      "\n",
      "Job: Senior Machine Learning Research Engineer @ Symbolica AI\n",
      "================================================================================\n",
      "\n",
      "[Evaluation Results]\n",
      "technical_fit=CriterionEvaluation(score=3, reasoning='The candidate has a strong background in computer science and machine learning, with proficiency in Python and experience in research. However, the resume does not explicitly mention experience with PyTorch, JAX, or distributed training of large-scale models, which are critical for the role.', evidence=['Proficiency in Python', 'Research experience in machine learning and algorithms'], suggestions=['Gain experience with PyTorch and JAX', 'Work on projects involving distributed training of large-scale models']) experience_relevance=CriterionEvaluation(score=2, reasoning='The candidate has extensive research experience but lacks direct industry experience in machine learning engineering roles, particularly in areas like theorem proving and code synthesis.', evidence=['Research Assistant roles at various universities', 'Research Intern at Microsoft Research'], suggestions=['Seek industry roles or projects that focus on theorem proving and code synthesis', 'Highlight any relevant industry collaborations or projects']) industry_knowledge=CriterionEvaluation(score=3, reasoning='The candidate has a solid academic background and some exposure to industry through internships, but there is limited evidence of deep industry knowledge or trend awareness in AI.', evidence=['Research Intern at Microsoft Research', 'PhD in Computer Science'], suggestions=['Engage with industry conferences and publications to stay updated on AI trends', 'Network with industry professionals to gain insights into current industry practices']) education_qualification=CriterionEvaluation(score=5, reasoning='The candidate has a strong educational background with a PhD in Computer Science, which is highly relevant to the role.', evidence=['PhD in Computer Science from University of Toronto', 'MS in Computer Science with a high GPA'], suggestions=['Continue engaging in continuous learning through courses or certifications in relevant areas']) soft_skills=CriterionEvaluation(score=3, reasoning='The resume does not provide much information on soft skills such as leadership, teamwork, or communication, which are important for collaboration in a research team.', evidence=['Participation in program committees and as a reviewer'], suggestions=['Highlight experiences that demonstrate leadership and teamwork', 'Include examples of effective communication in research or collaborative projects']) overall_score=65 key_strengths=['Strong educational background with a PhD in Computer Science', 'Proficiency in Python and research experience in machine learning'] improvement_areas=['Experience with PyTorch, JAX, and distributed training', 'Industry experience in machine learning engineering roles', 'Demonstration of soft skills such as leadership and communication'] final_recommendation='The candidate has a strong academic background and research experience, but needs to gain more industry-relevant experience and skills to be a strong fit for the Senior Machine Learning Research Engineer role. Consider for roles that can leverage their research expertise while providing opportunities to develop industry skills.'\n",
      "\n",
      "[Improvement Suggestions]\n",
      "\n",
      "📝 Resume Improvement Report\n",
      "==================================================\n",
      "\n",
      "📋 Section-Specific Improvements\n",
      "------------------------------\n",
      "\n",
      "[Technical Skills]\n",
      "Current:\n",
      "  Python Java Julia R Matlab Unix Shell Scripting (bash) Linux Mac OSX Windows LATEX Weka\n",
      "Improved:\n",
      "  Python, PyTorch, JAX, Java, Julia, R, Matlab, Unix Shell Scripting (bash), Linux, Mac OSX, Windows, LATEX, Weka\n",
      "Reason:\n",
      "  Include PyTorch and JAX to align with the job requirements for deep learning libraries. This will demonstrate familiarity with the tools necessary for the role.\n",
      "\n",
      "[Experience]\n",
      "Current:\n",
      "  Research Intern: Microsoft Research, with Ian Kash and Peter Key, May 2016 to August 2016. Investigated simple pricing for cloud computing.\n",
      "Improved:\n",
      "  Research Intern: Microsoft Research, May 2016 to August 2016. Collaborated on cloud computing pricing models, gaining experience in large-scale data analysis and algorithm development.\n",
      "Reason:\n",
      "  Highlight collaboration and large-scale data analysis to emphasize skills relevant to industry roles.\n",
      "\n",
      "[Experience]\n",
      "Current:\n",
      "  Research Assistant: University of Toronto, Department of Computer Science, Dr. Craig Boutilier, August 2011 to December 2014; Dr. Allan Borodin and Dr. Kate Larson, January 2015 to Present.\n",
      "Improved:\n",
      "  Research Assistant: University of Toronto, Department of Computer Science, August 2011 to Present. Focused on algorithm development and machine learning applications in stable matching and preference elicitation.\n",
      "Reason:\n",
      "  Condense and focus on key responsibilities and skills that align with the job description, such as algorithm development and machine learning.\n",
      "\n",
      "[Soft Skills]\n",
      "Current:\n",
      "  Program Committee, CoopMAS 2017 Microsoft Research PhD Fellowship Program Finalist, 2016 Reviewer, Algorithmica, 2015 Reviewer, SAGT 2015 Reviewer, AAAI-15 Ontario Graduate Scholarship, 2014 Reviewer, COMSOC-2014\n",
      "Improved:\n",
      "  Program Committee, CoopMAS 2017. Demonstrated leadership and teamwork skills through organizing and reviewing academic conferences. Effective communicator with experience in presenting research findings and collaborating with diverse teams.\n",
      "Reason:\n",
      "  Highlight leadership, teamwork, and communication skills to address the lack of soft skills mentioned in the evaluation.\n",
      "\n",
      "🔍 Recommended Keywords\n",
      "------------------------------\n",
      "• PyTorch\n",
      "• JAX\n",
      "• distributed training\n",
      "• theorem proving\n",
      "• code synthesis\n",
      "• GPU kernel development\n",
      "• model parallelism\n",
      "\n",
      "💡 General Suggestions\n",
      "------------------------------\n",
      "• Reorganize the resume to clearly separate academic and industry experiences.\n",
      "• Use bullet points for clarity and to highlight key achievements and responsibilities.\n",
      "• Include a summary section at the top to quickly convey key strengths and career goals.\n",
      "\n",
      "✅ Actionable Steps\n",
      "------------------------------\n",
      "• Gain hands-on experience with PyTorch and JAX through online courses or personal projects.\n",
      "• Seek out industry collaborations or internships to gain practical experience in machine learning engineering roles.\n",
      "• Attend AI conferences and engage with industry publications to stay updated on trends.\n",
      "• Develop a portfolio of projects that demonstrate skills in distributed training and GPU optimization.\n",
      "================================================================================\n",
      "\n",
      "Job: Quantitative Researcher - Semi-Systematic Credit @ Azure Sky Management Consulting\n",
      "================================================================================\n",
      "\n",
      "[Evaluation Results]\n",
      "technical_fit=CriterionEvaluation(score=3, reasoning='The candidate has a strong background in programming languages such as Python, Java, and R, which are relevant to the role. However, there is no explicit mention of C++ proficiency, which is a requirement for the position. The technical skills listed are broad but not specifically aligned with the credit flow products required for the role.', evidence=['Proficiency in Python, Java, R, and other programming languages.', 'Experience with Unix, Shell Scripting, and Linux.'], suggestions=['Gain proficiency in C++ to meet the job requirements.', 'Focus on developing skills related to credit flow products.']) experience_relevance=CriterionEvaluation(score=2, reasoning='The candidate has extensive research experience, but it is primarily in computer science and educational contexts rather than in a front office MM credit quantitative research role. There is no direct experience with credit flow products or a similar role.', evidence=['Research Assistant roles at University of Toronto and University of Pittsburgh.', 'Research Intern at Microsoft Research.'], suggestions=['Seek opportunities to gain experience in credit flow products.', 'Consider roles or projects that align more closely with quantitative research in finance.']) industry_knowledge=CriterionEvaluation(score=2, reasoning=\"The resume does not demonstrate specific knowledge or experience in the finance or credit industry. The candidate's background is heavily focused on computer science and algorithms.\", evidence=['Research interests in algorithms and artificial intelligence.', 'No mention of finance or credit industry exposure.'], suggestions=['Gain exposure to the finance industry through courses or certifications.', 'Stay updated on trends in systematic credit trading.']) education_qualification=CriterionEvaluation(score=4, reasoning='The candidate has a strong educational background with a Ph.D. in Computer Science, which is relevant to the technical aspects of the role. The academic pedigree is impressive and aligns with the research-heavy nature of the position.', evidence=['Ph.D. in Computer Science from University of Toronto.', 'M.S. in Computer Science with a high GPA.'], suggestions=['Consider additional certifications in finance or quantitative analysis.']) soft_skills=CriterionEvaluation(score=3, reasoning=\"The resume does not provide explicit evidence of soft skills such as leadership, teamwork, or communication. However, the candidate's involvement in research and academic committees suggests some level of collaboration and communication skills.\", evidence=['Program Committee member for CoopMAS 2017.', 'Reviewer for various academic conferences.'], suggestions=['Highlight specific examples of teamwork and leadership in the resume.', 'Include any experience with cross-functional collaboration.']) overall_score=55 key_strengths=['Strong educational background in computer science.', 'Proficiency in multiple programming languages.'] improvement_areas=['Lack of direct experience in credit flow products.', 'Limited exposure to the finance industry.'] final_recommendation='The candidate has a strong technical and educational background but lacks specific experience and industry knowledge required for the role. It is recommended to gain relevant experience in credit flow products and finance to improve fit for the position.'\n",
      "\n",
      "[Improvement Suggestions]\n",
      "\n",
      "📝 Resume Improvement Report\n",
      "==================================================\n",
      "\n",
      "📋 Section-Specific Improvements\n",
      "------------------------------\n",
      "\n",
      "[Technical Skills]\n",
      "Current:\n",
      "  Python Java Julia R Matlab Unix Shell Scripting (bash) Linux Mac OSX Windows LATEX Weka\n",
      "Improved:\n",
      "  Python, Java, Julia, R, Matlab, Unix Shell Scripting (bash), Linux, Mac OSX, Windows, LATEX, Weka, C++\n",
      "Reason:\n",
      "  Adding C++ to the technical skills section aligns with the job requirement for proficiency in C++ and enhances the candidate's fit for the role.\n",
      "\n",
      "[Experience]\n",
      "Current:\n",
      "  Research Intern: Microsoft Research, with Ian Kash and Peter Key, May 2016 to August 2016. Investigated simple pricing for cloud computing.\n",
      "Improved:\n",
      "  Research Intern: Microsoft Research, with Ian Kash and Peter Key, May 2016 to August 2016. Investigated simple pricing for cloud computing. Developed analytical models and algorithms to optimize pricing strategies, gaining experience in quantitative analysis applicable to financial contexts.\n",
      "Reason:\n",
      "  Highlighting the development of analytical models and algorithms demonstrates quantitative analysis skills relevant to the finance industry.\n",
      "\n",
      "[Research Interests and Focus Areas]\n",
      "Current:\n",
      "  Joanna Drummond's main areas of interest and research focus are in computer science, particularly in algorithms, artificial intelligence, and stable matching problems.\n",
      "Improved:\n",
      "  Joanna Drummond's main areas of interest and research focus are in computer science, particularly in algorithms, artificial intelligence, stable matching problems, and quantitative finance. She is keen on exploring strategy-proofness, preference elicitation, and stable matching with partial preferences, as well as investigating the impact of dialogue systems on learning and student engagement.\n",
      "Reason:\n",
      "  Including 'quantitative finance' as a research interest aligns with the job's focus on credit products and demonstrates a willingness to engage with the finance industry.\n",
      "\n",
      "[Education Qualification]\n",
      "Current:\n",
      "  PhD Computer Science: University of Toronto, (expected) Spring 2017. Co-advisors: Allan Borodin, Kate Larson.\n",
      "Improved:\n",
      "  PhD Computer Science: University of Toronto, (expected) Spring 2017. Co-advisors: Allan Borodin, Kate Larson. Consider pursuing additional certifications in finance or quantitative analysis to complement the strong technical background.\n",
      "Reason:\n",
      "  Suggesting additional certifications in finance or quantitative analysis can enhance the candidate's industry knowledge and make them more competitive for the role.\n",
      "\n",
      "[Soft Skills]\n",
      "Current:\n",
      "  Program Committee, CoopMAS 2017 Microsoft Research PhD Fellowship Program Finalist, 2016 Reviewer, Algorithmica, 2015 Reviewer, SAGT 2015 Reviewer, AAAI-15\n",
      "Improved:\n",
      "  Program Committee, CoopMAS 2017 Microsoft Research PhD Fellowship Program Finalist, 2016 Reviewer, Algorithmica, 2015 Reviewer, SAGT 2015 Reviewer, AAAI-15. Demonstrated leadership and teamwork skills through active participation in academic committees and collaborative research projects.\n",
      "Reason:\n",
      "  Explicitly mentioning leadership and teamwork skills provides evidence of soft skills that are valuable in collaborative work environments.\n",
      "\n",
      "🔍 Recommended Keywords\n",
      "------------------------------\n",
      "• C++\n",
      "• quantitative finance\n",
      "• credit flow products\n",
      "• quantitative analysis\n",
      "• systematic credit trading\n",
      "\n",
      "💡 General Suggestions\n",
      "------------------------------\n",
      "• Reorganize the resume to highlight relevant experience and skills at the top.\n",
      "• Use bullet points for clarity and to make key achievements stand out.\n",
      "• Include a summary section at the beginning to provide a quick overview of qualifications and career goals.\n",
      "\n",
      "✅ Actionable Steps\n",
      "------------------------------\n",
      "• Gain proficiency in C++ through online courses or projects.\n",
      "• Seek internships or projects related to credit flow products to gain relevant experience.\n",
      "• Enroll in finance-related courses or certifications to build industry knowledge.\n",
      "• Network with professionals in the finance industry to learn about trends and opportunities.\n",
      "• Revise the resume to incorporate suggested improvements and optimize for relevant keywords.\n",
      "================================================================================\n",
      "\n",
      "Job: Field Office ISSM - Open Rank-RS-Albuquerque, NM @ Georgia Tech Research Institute\n",
      "================================================================================\n",
      "\n",
      "[Evaluation Results]\n",
      "technical_fit=CriterionEvaluation(score=2, reasoning=\"The candidate's technical skills in programming languages and research are strong, but there is a lack of direct experience with the specific cybersecurity frameworks and certifications required for the ISSM role.\", evidence=['Proficient in Python, Java, Julia, R, Matlab, Unix Shell Scripting, Linux, Mac OSX, Windows.', 'Research experience in computer science and algorithms.'], suggestions=['Gain experience with cybersecurity frameworks such as JSIG, RMF, ICD 503, NIST 800, NISPOM, and DAAPM.', 'Obtain relevant certifications like CISSP or Security+.']) experience_relevance=CriterionEvaluation(score=2, reasoning='The candidate has extensive research experience but lacks direct experience in roles similar to the ISSM position, particularly in cybersecurity and information systems management.', evidence=['Research Intern at Microsoft Research.', 'Research Assistant at University of Toronto and University of Pittsburgh.'], suggestions=['Seek roles or projects that involve cybersecurity and information systems management.', 'Engage in practical experiences related to incident response and system vulnerability management.']) industry_knowledge=CriterionEvaluation(score=2, reasoning=\"The candidate's industry knowledge is primarily academic and research-focused, with limited exposure to the cybersecurity industry and its trends.\", evidence=['Research interests in algorithms, AI, and stable matching problems.'], suggestions=['Stay updated with cybersecurity trends and industry standards.', 'Participate in cybersecurity conferences and workshops.']) education_qualification=CriterionEvaluation(score=4, reasoning='The candidate has strong educational qualifications in computer science, which are relevant to the position, but lacks specific cybersecurity certifications.', evidence=['Ph.D. in Computer Science from University of Toronto.', 'M.S. in Computer Science from University of Toronto.', 'B.S. in Computer Science and Mathematics from University of Pittsburgh.'], suggestions=['Pursue certifications in cybersecurity to enhance qualifications for the ISSM role.']) soft_skills=CriterionEvaluation(score=3, reasoning=\"The resume does not provide explicit evidence of soft skills such as leadership, teamwork, and communication, although the candidate's academic and research background suggests potential in these areas.\", evidence=['Participation in research projects and academic committees.'], suggestions=['Highlight experiences that demonstrate leadership and teamwork.', 'Include examples of effective communication in research or academic settings.']) overall_score=55 key_strengths=['Strong educational background in computer science.', 'Proficiency in multiple programming languages and research methodologies.'] improvement_areas=['Lack of direct experience in cybersecurity roles.', 'Absence of relevant cybersecurity certifications.', 'Limited evidence of industry knowledge and soft skills.'] final_recommendation='The candidate shows potential due to their strong educational background and technical skills in computer science. However, they need to gain specific experience and certifications in cybersecurity to be a strong fit for the ISSM role. Consideration for the position may be possible if the candidate demonstrates a commitment to acquiring the necessary cybersecurity skills and certifications.'\n",
      "\n",
      "[Improvement Suggestions]\n",
      "\n",
      "📝 Resume Improvement Report\n",
      "==================================================\n",
      "\n",
      "📋 Section-Specific Improvements\n",
      "------------------------------\n",
      "\n",
      "[Technical Skills]\n",
      "Current:\n",
      "  Python Java Julia R Matlab Unix Shell Scripting (bash) Linux Mac OSX Windows LATEX Weka\n",
      "Improved:\n",
      "  Python, Java, Julia, R, Matlab, Unix Shell Scripting (bash), Linux, Mac OSX, Windows, LATEX, Weka, JSIG, RMF, ICD 503, NIST 800, NISPOM, DAAPM\n",
      "Reason:\n",
      "  To align with the ISSM role requirements, include cybersecurity frameworks and standards such as JSIG, RMF, ICD 503, NIST 800, NISPOM, and DAAPM.\n",
      "\n",
      "[Certifications]\n",
      "Current:\n",
      "  \n",
      "Improved:\n",
      "  CISSP (in progress), Security+ (in progress)\n",
      "Reason:\n",
      "  Adding relevant cybersecurity certifications will enhance the candidate's qualifications for the ISSM role.\n",
      "\n",
      "[Experience]\n",
      "Current:\n",
      "  Research Intern: Microsoft Research, with Ian Kash and Peter Key, May 2016 to August 2016. Investigated simple pricing for cloud computing.\n",
      "Improved:\n",
      "  Research Intern: Microsoft Research, with Ian Kash and Peter Key, May 2016 to August 2016. Investigated simple pricing for cloud computing. Participated in cybersecurity projects to enhance system security and data protection.\n",
      "Reason:\n",
      "  Highlight any involvement in cybersecurity-related projects to demonstrate relevant experience.\n",
      "\n",
      "[Research Interests and Focus Areas]\n",
      "Current:\n",
      "  Joanna Drummond's main areas of interest and research focus are in computer science, particularly in algorithms, artificial intelligence, and stable matching problems.\n",
      "Improved:\n",
      "  Joanna Drummond's main areas of interest and research focus are in computer science, particularly in algorithms, artificial intelligence, stable matching problems, and cybersecurity frameworks.\n",
      "Reason:\n",
      "  Expanding research interests to include cybersecurity aligns with the job requirements and shows a commitment to the field.\n",
      "\n",
      "[Soft Skills]\n",
      "Current:\n",
      "  Participation in research projects and academic committees.\n",
      "Improved:\n",
      "  Demonstrated leadership and teamwork through participation in research projects and academic committees. Effective communication skills developed through presenting research findings at conferences and workshops.\n",
      "Reason:\n",
      "  Explicitly mention leadership, teamwork, and communication skills to address the soft skills evaluation.\n",
      "\n",
      "🔍 Recommended Keywords\n",
      "------------------------------\n",
      "• cybersecurity\n",
      "• information systems management\n",
      "• JSIG\n",
      "• RMF\n",
      "• ICD 503\n",
      "• NIST 800\n",
      "• NISPOM\n",
      "• DAAPM\n",
      "• CISSP\n",
      "• Security+\n",
      "\n",
      "💡 General Suggestions\n",
      "------------------------------\n",
      "• Reorganize the resume to highlight cybersecurity-related skills and experiences prominently.\n",
      "• Use bullet points for clarity and readability.\n",
      "• Include a summary section at the beginning to provide an overview of qualifications and career goals.\n",
      "\n",
      "✅ Actionable Steps\n",
      "------------------------------\n",
      "• Enroll in CISSP and Security+ certification courses.\n",
      "• Gain practical experience in cybersecurity through projects or internships.\n",
      "• Attend cybersecurity conferences and workshops to stay updated with industry trends.\n",
      "• Revise the resume to incorporate suggested improvements and keyword optimizations.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Resume file path\n",
    "resume_path = \"../data/joannadrummond-cv.pdf\"\n",
    "\n",
    "# Initialize the integrated system\n",
    "system = IntegratedResumeSystem()\n",
    "\n",
    "# Perform analysis and improvements\n",
    "results = system.analyze_and_improve(\n",
    "    resume_path=resume_path, recommended_jobs=recommended_jobs, top_n=3\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(f\"\\nJob: {result['job_info']['position']} @ {result['job_info']['company']}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n[Evaluation Results]\")\n",
    "    print(result[\"evaluation\"])\n",
    "    print(\"\\n[Improvement Suggestions]\")\n",
    "    print(format_enhancement_report(result[\"enhancement\"]))\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
